{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "import os # for detecting CPU cores\n",
    "import numpy as np\n",
    "import configparser # to load standard config and parameters\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from icecream import ic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext watermark\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs used: 8\n"
     ]
    }
   ],
   "source": [
    "# Load external config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../src/config.ini\")\n",
    "\n",
    "PATH_DATA_RAW = config[\"PATHS\"][\"PATH_DATA_RAW\"]\n",
    "PATH_DATA_INT = config[\"PATHS\"][\"PATH_DATA_INT\"]\n",
    "PATH_DATA_PRO = config[\"PATHS\"][\"PATH_DATA_PRO\"]\n",
    "PATH_REPORTS = config[\"PATHS\"][\"PATH_REPORTS\"]\n",
    "PATH_MODELS = config[\"PATHS\"][\"PATH_MODELS\"]\n",
    "PATH_SUB = config[\"PATHS\"][\"PATH_SUB\"]\n",
    "\n",
    "# Telegram Bot\n",
    "token = config[\"TELEGRAM\"][\"token\"]\n",
    "chat_id = config[\"TELEGRAM\"][\"chat_id\"]\n",
    "FILENAME_NB = \"06_DL_model_submission\" # for Telegram messages\n",
    "\n",
    "# Set global randome state\n",
    "rnd_state = 42\n",
    "\n",
    "# Define available cpu cores\n",
    "n_cpu = os.cpu_count()\n",
    "print(\"Number of CPUs used:\", n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, requests #for Telegram notifications\n",
    "\n",
    "def send_telegram_message(message):\n",
    "    \"\"\"Sending messages to Telegram bot via requests.get().\"\"\"\n",
    "    \n",
    "    message = f\"{FILENAME_NB}:\\n{message}\"\n",
    "\n",
    "    # Using \"try and except\" to ensure that the notebook execution will not be stopped only because of problems with the bot.\n",
    "    # Example: No network connection.\n",
    "    # ISSUE: Be careful, an error messages will leak your Telegram Bot Token when uploaded to GitHub.\n",
    "    try:\n",
    "        url = 'https://api.telegram.org/bot%s/sendMessage?chat_id=%s&text=%s'%(token, chat_id, urllib.parse.quote_plus(message))\n",
    "        _ = requests.get(url, timeout=10)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('\\n\\nSending message to Telegram Bot was not successful.\\n\\n')\n",
    "        print(e)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(PATH_DATA_INT+'train-opt.pkl')\n",
    "test_df = pd.read_pickle(PATH_DATA_INT+'test-opt.pkl')\n",
    "sample_df = pd.read_csv(PATH_DATA_RAW+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.59437</td>\n",
       "      <td>132.804001</td>\n",
       "      <td>3.18428</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.73238</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.09959</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>1.09862</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.97877</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.67336</td>\n",
       "      <td>76.533600</td>\n",
       "      <td>3.37825</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.27562</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.54594</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>3.46017</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.57786</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.49747</td>\n",
       "      <td>233.546005</td>\n",
       "      <td>2.19435</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.05687</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.80187</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>4.88300</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.14112</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>779.966980</td>\n",
       "      <td>1.89064</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.69800</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.50332</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>3.47439</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.96860</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.71542</td>\n",
       "      <td>156.128006</td>\n",
       "      <td>2.14772</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.15492</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.37145</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>1.91059</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.07481</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1          f2       f3        f4       f5       f6  \\\n",
       "0  0.106643  3.59437  132.804001  3.18428  0.081971  1.18859  3.73238   \n",
       "1  0.125021  1.67336   76.533600  3.37825  0.099400  5.09366  1.27562   \n",
       "2  0.036330  1.49747  233.546005  2.19435  0.026914  3.12694  5.05687   \n",
       "3 -0.014077  0.24600  779.966980  1.89064  0.006948  1.53112  2.69800   \n",
       "4 -0.003259  3.71542  156.128006  2.14772  0.018284  2.09859  4.15492   \n",
       "\n",
       "         f7       f8        f9  ...       f90      f91       f92       f93  \\\n",
       "0  2.266270  2.09959  0.012330  ...  0.010739  1.09862  0.013331 -0.011715   \n",
       "1 -0.471318  4.54594  0.037706  ...  0.135838  3.46017  0.017054  0.124863   \n",
       "2  3.849460  1.80187  0.056995  ...  0.117310  4.88300  0.085222  0.032396   \n",
       "3  4.517330  4.50332  0.123494  ... -0.015347  3.47439 -0.017103 -0.008100   \n",
       "4 -0.038236  3.37145  0.034166  ...  0.013781  1.91059 -0.042943  0.105616   \n",
       "\n",
       "        f94       f95       f96      f97       f98       f99  \n",
       "0  0.052759  0.065400  4.211250  1.97877  0.085974  0.240496  \n",
       "1  0.154064  0.606848 -0.267928  2.57786 -0.020877  0.024719  \n",
       "2  0.116092 -0.001689 -0.520069  2.14112  0.124464  0.148209  \n",
       "3  0.062013  0.041193  0.511657  1.96860  0.040017  0.044873  \n",
       "4  0.125072  0.037509  1.043790  1.07481 -0.012819  0.072798  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = train_df.drop(['id','target'], axis=1).columns\n",
    "feature_cols = features_num.to_list()\n",
    "X = train_df.drop(['id','target'], axis=1).copy()\n",
    "y = train_df['target'].copy()\n",
    "X_test = test_df.drop(['id'], axis=1).copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705771</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>-0.872508</td>\n",
       "      <td>-0.258806</td>\n",
       "      <td>-0.595537</td>\n",
       "      <td>-0.199502</td>\n",
       "      <td>-0.196145</td>\n",
       "      <td>1.067358</td>\n",
       "      <td>-0.400887</td>\n",
       "      <td>-0.167145</td>\n",
       "      <td>0.443374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573313</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>-0.252018</td>\n",
       "      <td>0.548089</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>2.392937</td>\n",
       "      <td>-1.806811</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>-0.412110</td>\n",
       "      <td>-0.371198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408845</td>\n",
       "      <td>1.580886</td>\n",
       "      <td>-0.127714</td>\n",
       "      <td>-0.226174</td>\n",
       "      <td>-0.062423</td>\n",
       "      <td>-0.516946</td>\n",
       "      <td>-1.968603</td>\n",
       "      <td>-0.294434</td>\n",
       "      <td>-0.078904</td>\n",
       "      <td>0.094984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.768719</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>-0.314304</td>\n",
       "      <td>-0.565262</td>\n",
       "      <td>-0.179472</td>\n",
       "      <td>-0.311897</td>\n",
       "      <td>-1.306572</td>\n",
       "      <td>-0.407556</td>\n",
       "      <td>-0.272505</td>\n",
       "      <td>-0.295118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510155</td>\n",
       "      <td>-0.346112</td>\n",
       "      <td>-0.361423</td>\n",
       "      <td>0.386926</td>\n",
       "      <td>-0.042986</td>\n",
       "      <td>-0.329511</td>\n",
       "      <td>-0.965117</td>\n",
       "      <td>-0.993613</td>\n",
       "      <td>-0.393636</td>\n",
       "      <td>-0.189697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.382553  0.705771 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1 -0.347377 -0.530387 -0.417061  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2 -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3 -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4 -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.197064 -0.286162 -0.289270  ... -0.537157 -0.872508 -0.258806 -0.595537   \n",
       "1 -1.963980  1.309644 -0.229122  ...  0.573313  0.658473 -0.252018  0.548089   \n",
       "2  0.824771 -0.480372 -0.183401  ...  0.408845  1.580886 -0.127714 -0.226174   \n",
       "3  1.255833  1.281843 -0.025780  ... -0.768719  0.667692 -0.314304 -0.565262   \n",
       "4 -1.684456  0.543499 -0.237512  ... -0.510155 -0.346112 -0.361423  0.386926   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.199502 -0.196145  1.067358 -0.400887 -0.167145  0.443374  \n",
       "1  0.019765  2.392937 -1.806811 -0.008064 -0.412110 -0.371198  \n",
       "2 -0.062423 -0.516946 -1.968603 -0.294434 -0.078904  0.094984  \n",
       "3 -0.179472 -0.311897 -1.306572 -0.407556 -0.272505 -0.295118  \n",
       "4 -0.042986 -0.329511 -0.965117 -0.993613 -0.393636 -0.189697  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling all values\n",
    "s_scaler = StandardScaler()\n",
    "for col in feature_cols:\n",
    "    X[col] = s_scaler.fit_transform(np.array(X[col]).reshape(-1,1))\n",
    "    X_test[col] = s_scaler.transform(np.array(X_test[col]).reshape(-1,1))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| n_clusters_1: 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters_1 = 9\n",
    "cluster_cols = [f\"cluster{i+1}\" for i in range(n_clusters_1)]\n",
    "#kmeans = KMeans(n_clusters=n_clusters_1, n_init=50, max_iter=500, random_state=rnd_state)\n",
    "kmeans = KMeans(n_clusters=n_clusters_1, init=\"k-means++\", max_iter=500, random_state=rnd_state)\n",
    "\n",
    "ic(n_clusters_1);\n",
    "#ic(cluster_cols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster distance instead of cluster number\n",
    "\n",
    "# train\n",
    "X_cd = kmeans.fit_transform(X[feature_cols])\n",
    "X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=train_df.index)\n",
    "X = X.join(X_cd)\n",
    "\n",
    "# test\n",
    "X_cd = kmeans.transform(X_test[feature_cols])\n",
    "X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=test_df.index)\n",
    "X_test = X_test.join(X_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(feature_cols): 109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f99</th>\n",
       "      <th>cluster1</th>\n",
       "      <th>cluster2</th>\n",
       "      <th>cluster3</th>\n",
       "      <th>cluster4</th>\n",
       "      <th>cluster5</th>\n",
       "      <th>cluster6</th>\n",
       "      <th>cluster7</th>\n",
       "      <th>cluster8</th>\n",
       "      <th>cluster9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705771</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443374</td>\n",
       "      <td>13.524524</td>\n",
       "      <td>13.255687</td>\n",
       "      <td>13.700806</td>\n",
       "      <td>14.274994</td>\n",
       "      <td>12.859630</td>\n",
       "      <td>12.957320</td>\n",
       "      <td>36.129147</td>\n",
       "      <td>14.155483</td>\n",
       "      <td>13.117831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371198</td>\n",
       "      <td>10.190652</td>\n",
       "      <td>9.777174</td>\n",
       "      <td>10.614064</td>\n",
       "      <td>11.234878</td>\n",
       "      <td>10.152011</td>\n",
       "      <td>9.488068</td>\n",
       "      <td>35.085693</td>\n",
       "      <td>10.948878</td>\n",
       "      <td>10.155034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094984</td>\n",
       "      <td>8.555525</td>\n",
       "      <td>7.960729</td>\n",
       "      <td>8.872967</td>\n",
       "      <td>9.686649</td>\n",
       "      <td>8.570546</td>\n",
       "      <td>7.778075</td>\n",
       "      <td>34.809380</td>\n",
       "      <td>9.578272</td>\n",
       "      <td>8.652298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295118</td>\n",
       "      <td>16.142862</td>\n",
       "      <td>15.755400</td>\n",
       "      <td>16.347662</td>\n",
       "      <td>16.765732</td>\n",
       "      <td>16.229053</td>\n",
       "      <td>15.869077</td>\n",
       "      <td>37.083992</td>\n",
       "      <td>16.634487</td>\n",
       "      <td>16.166260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189697</td>\n",
       "      <td>8.511835</td>\n",
       "      <td>7.657890</td>\n",
       "      <td>8.973676</td>\n",
       "      <td>9.729104</td>\n",
       "      <td>8.658287</td>\n",
       "      <td>8.013620</td>\n",
       "      <td>34.997364</td>\n",
       "      <td>9.153749</td>\n",
       "      <td>8.548615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.382553  0.705771 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1 -0.347377 -0.530387 -0.417061  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2 -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3 -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4 -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "\n",
       "         f7        f8        f9  ...       f99   cluster1   cluster2  \\\n",
       "0 -0.197064 -0.286162 -0.289270  ...  0.443374  13.524524  13.255687   \n",
       "1 -1.963980  1.309644 -0.229122  ... -0.371198  10.190652   9.777174   \n",
       "2  0.824771 -0.480372 -0.183401  ...  0.094984   8.555525   7.960729   \n",
       "3  1.255833  1.281843 -0.025780  ... -0.295118  16.142862  15.755400   \n",
       "4 -1.684456  0.543499 -0.237512  ... -0.189697   8.511835   7.657890   \n",
       "\n",
       "    cluster3   cluster4   cluster5   cluster6   cluster7   cluster8   cluster9  \n",
       "0  13.700806  14.274994  12.859630  12.957320  36.129147  14.155483  13.117831  \n",
       "1  10.614064  11.234878  10.152011   9.488068  35.085693  10.948878  10.155034  \n",
       "2   8.872967   9.686649   8.570546   7.778075  34.809380   9.578272   8.652298  \n",
       "3  16.347662  16.765732  16.229053  15.869077  37.083992  16.634487  16.166260  \n",
       "4   8.973676   9.729104   8.658287   8.013620  34.997364   9.153749   8.548615  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols += cluster_cols\n",
    "ic(len(feature_cols));\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "\n",
    "X_poly = poly.fit_transform(X[cluster_cols])\n",
    "T_poly = poly.transform(X_test[cluster_cols])\n",
    "\n",
    "poly_cols = [f\"cluster_poly{i+1}\" for i in range(X_poly.shape[1])]\n",
    "\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly_cols, index=X.index)\n",
    "T_poly_df = pd.DataFrame(T_poly, columns=poly_cols, index=X_test.index)\n",
    "\n",
    "X = pd.concat([X, X_poly_df], axis=1)\n",
    "X_test = pd.concat([X_test, T_poly_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(feature_cols): 155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_poly37</th>\n",
       "      <th>cluster_poly38</th>\n",
       "      <th>cluster_poly39</th>\n",
       "      <th>cluster_poly40</th>\n",
       "      <th>cluster_poly41</th>\n",
       "      <th>cluster_poly42</th>\n",
       "      <th>cluster_poly43</th>\n",
       "      <th>cluster_poly44</th>\n",
       "      <th>cluster_poly45</th>\n",
       "      <th>cluster_poly46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705771</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>166.626343</td>\n",
       "      <td>464.607452</td>\n",
       "      <td>182.034271</td>\n",
       "      <td>168.690445</td>\n",
       "      <td>468.136932</td>\n",
       "      <td>183.417130</td>\n",
       "      <td>169.971939</td>\n",
       "      <td>511.425537</td>\n",
       "      <td>473.936035</td>\n",
       "      <td>185.689240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>96.322968</td>\n",
       "      <td>356.190338</td>\n",
       "      <td>111.153130</td>\n",
       "      <td>103.094017</td>\n",
       "      <td>332.895416</td>\n",
       "      <td>103.883698</td>\n",
       "      <td>96.351646</td>\n",
       "      <td>384.148987</td>\n",
       "      <td>356.296417</td>\n",
       "      <td>111.186234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>66.662346</td>\n",
       "      <td>298.335388</td>\n",
       "      <td>82.091019</td>\n",
       "      <td>74.154922</td>\n",
       "      <td>270.749969</td>\n",
       "      <td>74.500511</td>\n",
       "      <td>67.298218</td>\n",
       "      <td>333.413696</td>\n",
       "      <td>301.181122</td>\n",
       "      <td>82.874062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>257.540100</td>\n",
       "      <td>601.838074</td>\n",
       "      <td>269.961975</td>\n",
       "      <td>262.363098</td>\n",
       "      <td>588.488708</td>\n",
       "      <td>263.973938</td>\n",
       "      <td>256.543610</td>\n",
       "      <td>616.873169</td>\n",
       "      <td>599.509460</td>\n",
       "      <td>268.917450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>69.384224</td>\n",
       "      <td>303.017212</td>\n",
       "      <td>79.255783</td>\n",
       "      <td>74.016365</td>\n",
       "      <td>280.455597</td>\n",
       "      <td>73.354668</td>\n",
       "      <td>68.505356</td>\n",
       "      <td>320.357056</td>\n",
       "      <td>299.179016</td>\n",
       "      <td>78.251877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.382553  0.705771 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1 -0.347377 -0.530387 -0.417061  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2 -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3 -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4 -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "\n",
       "         f7        f8        f9  ...  cluster_poly37  cluster_poly38  \\\n",
       "0 -0.197064 -0.286162 -0.289270  ...      166.626343      464.607452   \n",
       "1 -1.963980  1.309644 -0.229122  ...       96.322968      356.190338   \n",
       "2  0.824771 -0.480372 -0.183401  ...       66.662346      298.335388   \n",
       "3  1.255833  1.281843 -0.025780  ...      257.540100      601.838074   \n",
       "4 -1.684456  0.543499 -0.237512  ...       69.384224      303.017212   \n",
       "\n",
       "   cluster_poly39  cluster_poly40  cluster_poly41  cluster_poly42  \\\n",
       "0      182.034271      168.690445      468.136932      183.417130   \n",
       "1      111.153130      103.094017      332.895416      103.883698   \n",
       "2       82.091019       74.154922      270.749969       74.500511   \n",
       "3      269.961975      262.363098      588.488708      263.973938   \n",
       "4       79.255783       74.016365      280.455597       73.354668   \n",
       "\n",
       "   cluster_poly43  cluster_poly44  cluster_poly45  cluster_poly46  \n",
       "0      169.971939      511.425537      473.936035      185.689240  \n",
       "1       96.351646      384.148987      356.296417      111.186234  \n",
       "2       67.298218      333.413696      301.181122       82.874062  \n",
       "3      256.543610      616.873169      599.509460      268.917450  \n",
       "4       68.505356      320.357056      299.179016       78.251877  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols += poly_cols\n",
    "ic(len(feature_cols));\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "transformer_num = make_pipeline(StandardScaler(),)\n",
    "\n",
    "preprocessor = make_column_transformer((transformer_num, feature_cols))\n",
    "\n",
    "# stratify - make sure classes are evenlly represented across splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, stratify=y, train_size=0.75, random_state=rnd_state\n",
    ")\n",
    "\n",
    "# X_train = preprocessor.fit_transform(X_train)\n",
    "# X_valid = preprocessor.transform(X_valid)\n",
    "# X_test = preprocessor.transform(X_test)\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "print(input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 502\n",
    "learning_rate = 0.00012239884711399426\n",
    "patience = 57\n",
    "n_units_l0 = 3\n",
    "n_units_l1 = 3\n",
    "epochs = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_3 (Batc  (None, 155)              620       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 468       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,104\n",
      "Trainable params: 794\n",
      "Non-trainable params: 310\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "# Set seed\n",
    "tf.random.set_seed(rnd_state)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=input_shape),\n",
    "        #layers.Dense(n_units_l0, activation=\"relu\"),\n",
    "        #layers.Dense(n_units_l1, activation=\"relu\"),\n",
    "        layers.Dense(n_units_l0, activation=\"swish\"),\n",
    "        layers.Dense(n_units_l1, activation=\"swish\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),  # sigmoid for binary output\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\", # for binary classification \n",
    "    metrics=[\"AUC\"],\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, min_delta=learning_rate, monitor='val_auc', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    #shuffle=True\n",
    "    verbose=0,  # hide the output because we have so many epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7543720006942749\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model accuracy on the validation set.\n",
    "score = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss: 0.568476\n",
      "Best Validation AUC: 0.754474\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA58ElEQVR4nO3deZhcVZ3/8fe3qpfqfd+7091JOntICE3CYgIIIYBIBFEDCNFRWRwQmMGR+ekg4+joAI6OgiJqRkQEMggSJYRVCMiWTuhsZOssnfSS3tL7XlXn98e5CZWml0p3J5VOf1/P00/VvXXvrXO6kvr0Oeeee8UYg1JKKTUQV6gLoJRS6uSmQaGUUmpQGhRKKaUGpUGhlFJqUBoUSimlBhUW6gIci9TUVFNQUBDqYiil1Jiyfv36emNM2nD3H1NBUVBQQElJSaiLoZRSY4qIlI9kf+16UkopNSgNCqWUUoPSoFBKKTWoMTVGoZQan3p7e6moqKCrqyvURTmpeTwecnNzCQ8PH9XjalAopU56FRUVxMXFUVBQgIiEujgnJWMMDQ0NVFRUUFhYOKrH1q4npdRJr6uri5SUFA2JQYgIKSkpx6XVpUGhlBoTNCSGdrx+R+MiKF7bXsMvXi8LdTGUUmpMGhdB8dauBn726i703htKqeGIjY0NdRFCalwERUFqNF29fmpbu0NdFKWUGnPGRVDkp8QAUN7QEeKSKKXGMmMM3/zmN5k1axazZ8/mqaeeAqC6uppFixYxd+5cZs2axZtvvonP5+NLX/rSkW1/8pOfhLj0wzcuTo8tSIkGYF9DO/MLk0NcGqXUSPz7X7byYVXLqB5zRnY83/30zCG3e+aZZygtLWXjxo3U19dz5plnsmjRIv74xz+yZMkSvv3tb+Pz+ejo6KC0tJTKykq2bNkCQFNT06iW+UQaFy2KnMQowlxCeUN7qIuilBrD3nrrLa655hrcbjcZGRmcd955rFu3jjPPPJP//d//5d5772Xz5s3ExcUxceJE9uzZw2233caaNWuIj48PdfGHbVy0KMLcLnKTotinXU9KjXnB/OV/vAx0QsyiRYtYu3Ytzz//PNdffz3f/OY3ueGGG9i4cSMvvvgiDz30ECtXrmTFihUnuMSjY1y0KMCOU+zXoFBKjcCiRYt46qmn8Pl81NXVsXbtWubPn095eTnp6el87Wtf4ytf+QobNmygvr4ev9/PZz/7Wf7jP/6DDRs2hLr4wzYuWhQA+SnRbChvxBijE3eUUsNy5ZVX8s477zBnzhxEhPvuu4/MzEweffRR7r//fsLDw4mNjeX3v/89lZWVfPnLX8bv9wPwwx/+MMSlH75xExQTU2No7fZS19pNerwn1MVRSo0hbW1tgJ35fP/993P//fcf9fry5ctZvnz5x/Yby62IQOOm62lKRhwAO2vaQlwSpZQaW8ZNUBQ5QbGjpjXEJVFKqbElqKAQkUtEZIeIlInI3QNsc76IlIrIVhF5Y6h9ReReEal09ikVkctGXp2BpcZGkBwTwS4NCqWUOiZDjlGIiBt4CFgMVADrRGSVMebDgG0SgV8Alxhj9otIepD7/sQY88BoVmiQelCUHqstCqWUOkbBtCjmA2XGmD3GmB7gSWBpn22uBZ4xxuwHMMbUHsO+x5/fD221TMmIo6ymTS8OqJRSxyCYoMgBDgQsVzjrAk0BkkTkdRFZLyI3BLnvrSKySURWiEhSf28uIjeKSImIlNTV1QVR3H785Rvwq0VMy4qjtdur13xSSqljEExQ9DfpoO+f5GHAGcCngCXAv4nIlCH2/SUwCZgLVAM/7u/NjTGPGGOKjTHFaWlpQRS3HymTobWaBVluAN7fe2h4x1FKqXEomKCoAPIClnOBqn62WWOMaTfG1ANrgTmD7WuMqTHG+IwxfuDX2G6q4yNtGgCTqCA5JoL3NCiUUsfRYPev2LdvH7NmzTqBpRm5YIJiHVAkIoUiEgEsA1b12eY5YKGIhIlINLAA2DbYviKSFbD/lcCWkVVlEOk2KKRuB2cWJPHe3obj9lZKKXWqGfKsJ2OMV0RuBV4E3MAKY8xWEbnZef1hY8w2EVkDbAL8wG+MMVsA+tvXOfR9IjIX2xW1D7hpVGsWKGEChEVB3XYWFC7ixa01VDZ1kpMYddzeUil1nLxwNxzcPLrHzJwNl/5owJe/9a1vkZ+fz9e//nUA7r33XkSEtWvX0tjYSG9vL9///vdZuvTYztXp6urilltuoaSkhLCwMP77v/+bCy64gK1bt/LlL3+Znp4e/H4/f/rTn8jOzubzn/88FRUV+Hw+/u3f/o0vfOELI6p2sIK6hIcxZjWwus+6h/ss3w8cPa99gH2d9dcfU0lHwuWCtCk2KE6z96N4b08DV83LPWFFUEqNXcuWLeOOO+44EhQrV65kzZo13HnnncTHx1NfX89ZZ53FFVdccUzXknvooYcA2Lx5M9u3b+fiiy9m586dPPzww9x+++1cd9119PT04PP5WL16NdnZ2Tz//PMANDc3j35FBzBurvVE2nTY9ybTMuOJ94Tx3p5DGhRKjUWD/OV/vJx++unU1tZSVVVFXV0dSUlJZGVlceedd7J27VpcLheVlZXU1NSQmZkZ9HHfeustbrvtNgCmTZtGfn4+O3fu5Oyzz+YHP/gBFRUVXHXVVRQVFTF79mzuuusuvvWtb3H55ZezcOHC41Xdjxk3l/AgYya0VOJur2F+YTLv79MBbaVU8K6++mqefvppnnrqKZYtW8bjjz9OXV0d69evp7S0lIyMDLq6uo7pmAPN6br22mtZtWoVUVFRLFmyhNdee40pU6awfv16Zs+ezb/+67/yve99bzSqFZTxExSFTvrufZMFhSnsrW+ntuXYPlSl1Pi1bNkynnzySZ5++mmuvvpqmpubSU9PJzw8nL/97W+Ul5cf8zEXLVrE448/DsDOnTvZv38/U6dOZc+ePUycOJFvfOMbXHHFFWzatImqqiqio6P54he/yF133XVCr0w7frqeMk8DTwLsfYP58xYD8O7eQ1wxJzvEBVNKjQUzZ86ktbWVnJwcsrKyuO666/j0pz9NcXExc+fOZdq0acd8zK9//evcfPPNzJ49m7CwMH73u98RGRnJU089xR/+8AfCw8PJzMzknnvuYd26dXzzm9/E5XIRHh7OL3/5y+NQy/7JWLqcRXFxsSkpKRn+AZ68Dg5uxntbKXO/9zJL52bzgytnj14BlVLHxbZt25g+fXqoizEm9Pe7EpH1xpji4R5z/HQ9ARQugqZywlorOSM/SSfeKaVUEMZP1xNA7pn2sbKEBRNnc9+aHdS3dZMaGxnacimlTjmbN2/m+uuPngUQGRnJe++9F6ISDd/4CoqMWRDmgYoSFkw7H4CSfYe4ZFbW4PsppUJurN3vfvbs2ZSWlp7Q9zxeQwnjq+spLAKy5kBFCTOz4wlzCZsqTtykFaXU8Hg8HhoaGvQWAYMwxtDQ0IDH4xn1Y4+vFgVATjGU/BaPy8+UjDg2V2pQKHWyy83NpaKigmHfamCc8Hg85OaO/kTi8RcUucXw7kNQs4XTchNYs/XgmGvSKjXehIeHU1hYGOpijFvjq+sJbFAAVJQwKyeBpo5eKho7Q1smpZQ6iY2/oEjIg9gMqCjhtNwEAB2nUEqpQYy/oBCx4xSVJUzJiMMlsONgS6hLpZRSJ63xFxQAuWdAQxme3mbyU2Ioq2sLdYmUUuqkNU6D4vDEuw1MSotlV40GhVJKDSSooBCRS0Rkh4iUicjdA2xzvoiUishWEXljqH1FJFlEXhaRXc5j0sirE6Ts0wGByhKKMmLZ19BOr89/wt5eKaXGkiGDQkTcwEPApcAM4BoRmdFnm0TgF8AVxpiZwOeC2Pdu4FVjTBHwqrN8YkTGQfp0qCihKD2WXp+hvKHjhL29UkqNJcG0KOYDZcaYPcaYHuBJoO+NYa8FnjHG7AcwxtQGse9S4FHn+aPAZ4Zdi+HItQPak9NiACirbT2hb6+UUmNFMEGRAxwIWK5w1gWaAiSJyOsisl5Ebghi3wxjTDWA85h+rIUfkZxi6GxkcpjNtLJaHadQSqn+BDMzu78py30vuBIGnAFcCEQB74jIu0HuO/ibi9wI3AgwYcKEY9l1cM6AdnTtB+QkprNLg0IppfoVTIuiAsgLWM4FqvrZZo0xpt0YUw+sBeYMsW+NiGQBOI+19MMY84gxptgYU5yWlhZEcYOUNhUiYqGihMnpeuaTUkoNJJigWAcUiUihiEQAy4BVfbZ5DlgoImEiEg0sALYNse8qYLnzfLlzjBPH5bZnP1XaAe3ddW34/HplSqWU6mvIoDDGeIFbgRexX/4rjTFbReRmEbnZ2WYbsAbYBLwP/MYYs2WgfZ1D/whYLCK7gMXO8omVeyYc3My01DC6vX4q9ZpPSin1MUFdPdYYsxpY3Wfdw32W7wfuD2ZfZ30DdkwjdHKLwe9llqscgF21rUxIiQ5pkZRS6mQzPmdmH5ZzBgD53TsBPfNJKaX6M76DIjYDopKIatpFamwku/WaT0op9THjOyhEIG0a1O1gQnIUBw7pGIVSSvU1voMC7GmyddvIS4riQKNexkMppfrSoEidCp2NTInrorq5C69eHFAppY6iQZE2FYBp7mp8fkN1c1eIC6SUUicXDYq0aQAU+O0lqbT7SSmljqZBEZ8N4TGk9digqNABbaWUOooGhQgkFxLbcQCXaItCKaX60qAASCrA1biXrIQoDhzSoFBKqUAaFADJE6GxnNzESKqadDBbKaUCaVAAJBeCr5vpMW1UNesYhVJKBdKgAEgqBGBaRB0Hm7v0cuNKKRVAgwJs1xOQ76rF6zfUt3WHuEBKKXXy0KAASMgFVzhZ/moAqpq0+0kppQ7ToAB7t7uEHJJ6agB0QFsppQJoUBwWn0NMtw2Kah3QVkqpI4IKChG5RER2iEiZiNzdz+vni0iziJQ6P/cEvHa7iGwRka0ickfA+ntFpDJgn8tGpUbDFZ+Du62a6Ai3tiiUUirAkLdCFRE38BD2vtYVwDoRWWWM+bDPpm8aYy7vs+8s4GvAfKAHWCMizxtjdjmb/MQY88BIKzEq4rOR1mqy4yO0RaGUUgGCaVHMB8qMMXuMMT3Ak8DSII8/HXjXGNNhjPECbwBXDq+ox1l8Dvh6mBrfo4PZSikVIJigyAEOBCxXOOv6OltENorICyIy01m3BVgkIikiEg1cBuQF7HOriGwSkRUiktTfm4vIjSJSIiIldXV1QRR3mOKzAZga1UqVXmpcKaWOCCYopJ91fWekbQDyjTFzgJ8DfwYwxmwD/gt4GVgDbAS8zj6/BCYBc4Fq4Mf9vbkx5hFjTLExpjgtLS2I4g6TExQFEU3UtXbT7fUdv/dSSqkxJJigqODoVkAuUBW4gTGmxRjT5jxfDYSLSKqz/FtjzDxjzCLgELDLWV9jjPEZY/zAr7FdXKGTkAtArrsRgJpmnXSnlFIQXFCsA4pEpFBEIoBlwKrADUQkU0TEeT7fOW6Ds5zuPE4ArgKecJazAg5xJbabKnSiU8EVTpq/AUCv+aSUUo4hz3oyxnhF5FbgRcANrDDGbBWRm53XHwauBm4RES/QCSwzxhzunvqTiKQAvcA/GmManfX3ichcbDfWPuCm0avWMLhcEJ9ForcW0LkUSil12JBBAUe6k1b3WfdwwPMHgQcH2HfhAOuvD76YJ0h8DtFdOjtbKaUC6czsQPHZuFurSIoO11NklVLKoUERKD4HWqrIivdQrafIKqUUoEFxtPgc8HUzRSfdKaXUERoUgZy5FFOiWjQolFLKoUERKN5OOC8Ib6Kly0tbt3eIHZRS6tSnQRHIaVHkOJPuqrVVoZRSGhRHiU0HVxhpph5Ar/mklFJoUBzN5Ya4LBJ67cUHtUWhlFIaFB8Xn01UZw0ieu9spZQCDYqPi8/G1VJJRpxHu56UUgoNio87POkuIVKv96SUUmhQfFx8Nng7mRznpVqv96SUUhoUH+PMpSjytFDZ1MlHF8FVSqnxSYOir8OT7iKa6Pb6aezoDXGBlFIqtDQo+jo86c7l3MBIz3xSSo1zGhR9xWaAuEj1a1AopRQEGRQicomI7BCRMhG5u5/XzxeRZhEpdX7uCXjtdhHZIiJbReSOgPXJIvKyiOxyHpNGpUYj5Q6D2MyPJt3pKbJKqXFuyKAQETfwEHApMAO4RkRm9LPpm8aYuc7P95x9ZwFfA+YDc4DLRaTI2f5u4FVjTBHwqrN8cojPJrLjIBFul947Wyk17gXTopgPlBlj9hhjeoAngaVBHn868K4xpsMY4wXeAK50XlsKPOo8fxT4TNClPt4ScpCWSjITPHpLVKXUuBdMUOQABwKWK5x1fZ0tIhtF5AURmems2wIsEpEUEYkGLgPynNcyjDHVAM5jen9vLiI3ikiJiJTU1dUFUdxREJcNLVVkJ0Tq9Z6UUuNeMEEh/azrO7lgA5BvjJkD/Bz4M4AxZhvwX8DLwBpgI3BMN3kwxjxijCk2xhSnpaUdy67DF58Nve1MjPPrGIVSatwLJigq+KgVAJALVAVuYIxpMca0Oc9XA+Eikuos/9YYM88Yswg4BOxydqsRkSwA57F2RDUZTc4pspOjWjjY0oXPr5PulFLjVzBBsQ4oEpFCEYkAlgGrAjcQkUwREef5fOe4Dc5yuvM4AbgKeMLZbRWw3Hm+HHhuZFUZRc6ku/ywJnx+Q22rtiqUUuNX2FAbGGO8InIr8CLgBlYYY7aKyM3O6w8DVwO3iIgX6ASWmY+uffEnEUkBeoF/NMY0Out/BKwUka8A+4HPjWbFRsRpUWS7G4EEqpq6yEqICm2ZlFIqRIYMCjjSnbS6z7qHA54/CDw4wL4LB1jfAFwYdElPpLgsAGfSXQFVTZ2ckX9yTPNQSqkTTWdm9ycsAmLSSei1wyZ6uXGl1HimQTGQ+CzC2w8SGxmmcymUUuOaBsVA4nOQliqyEjx6vSel1LimQTGQ+GxorSIrMUrnUiilxjUNioHEZ0NnIwXxOkahlBrfNCgG4sylmORppb6th65eX4gLpJRSoaFBMRBnLkV+WBMAB7X7SSk1TmlQDCTu8J3uDgHo5caVUuOWBsVA4u2kuxRj73RXrafIKqXGKQ2KgUTEgCeR+B57aXM9RVYpNV5pUAwmPoewtmqSYyKo0jEKpdQ4pUExmPhsaKkkO9Gjp8gqpcYtDYrBxNs73WUlRGnXk1Jq3NKgGEx8DrTXkhfn0sFspdS4pUExmKR8AKZ4mmjt9tLS1RviAiml1ImnQTGYRBsUBW575lPFIe1+UkqNP0EFhYhcIiI7RKRMRO7u5/XzRaRZREqdn3sCXrtTRLaKyBYReUJEPM76e0WkMmCfy0avWqPEaVHku2xQlNW1hbI0SikVEkPe4U5E3MBDwGKgAlgnIquMMR/22fRNY8zlffbNAb4BzDDGdIrISuw9t3/nbPITY8wDI6zD8RObCe5I0rwHcUkhZTWtoS6RUkqdcMG0KOYDZcaYPcaYHuBJYOkxvEcYECUiYUA0UHXsxQwRlwsSJxDWsp/8lBh21miLQik1/gQTFDnAgYDlCmddX2eLyEYReUFEZgIYYyqBB4D9QDXQbIx5KWCfW0Vkk4isEJF+b0otIjeKSImIlNTV1QVTp9GVlA+N+yhKj2VnrbYolFLjTzBBIf2sM32WNwD5xpg5wM+BPwM4X/5LgUIgG4gRkS86+/wSmATMxYbIj/t7c2PMI8aYYmNMcVpaWhDFHWVJBdBYzpSMOMobOuj26uXGlVLjSzBBUQHkBSzn0qf7yBjTYoxpc56vBsJFJBW4CNhrjKkzxvQCzwDnONvVGGN8xhg/8GtsF9fJJzEfupqYnuTH5zfsrW8PdYmUUuqECiYo1gFFIlIoIhHYwehVgRuISKaIiPN8vnPcBmyX01kiEu28fiGwzdkuK+AQVwJbRlqZ48I582m6pxGAXTpOoZQaZ4Y868kY4xWRW4EXATewwhizVURudl5/GLgauEVEvEAnsMwYY4D3RORpbNeUF/gAeMQ59H0iMhfbjbUPuGk0KzZqkgoAyJVaXBLOLj3zSSk1zgwZFHCkO2l1n3UPBzx/EHhwgH2/C3y3n/XXH1NJQ8WZdBfReoD8lNl65pNSatzRmdlDiUoET8KRM5926ZlPSqlxRoMiGM6ZT0UZsezTM5+UUuOMBkUwEvOhyZ4iq2c+KaXGGw2KYCTl27kU6TEA7Dio3U9KqfFDgyIYifng66Youh1PuIvSA02hLpFSSp0wGhTBSJ4IQFjTPmbnJGhQKKXGFQ2KYKRMto8NZczNS2RrVQs9Xn9oy6SUUieIBkUwEnLBHekERRI9Xj/bqltCXSqllDohNCiC4XLb7qeGMuZOSATQ7iel1LihQRGs1MnQUEZ2goe0uEgNCqXUuKFBEayUyXBoL+L3MTcvUYNCKTVuaFAEK2Uy+HuheT9z8xLZW99OU0dPqEullFLHnQZFsFKK7GPdTk7XcQql1DiiQRGstKn2sW4bp+Um4hLYUN4Y2jIppdQJoEERrKhEiMuG2u3ERoYxOzeRv+9uCHWplFLquNOgOBbp06D2QwA+MTmF0gNNtHT1hrhQSil1fAUVFCJyiYjsEJEyEbm7n9fPF5FmESl1fu4JeO1OEdkqIltE5AkR8Tjrk0XkZRHZ5TwmjV61jpP0GVC/E/w+PjE5DZ/f8N6eQ6EulVJKHVdDBoWIuIGHgEuBGcA1IjKjn03fNMbMdX6+5+ybA3wDKDbGzMLeSnWZs/3dwKvGmCLgVWf55JY2Dbxd0LiPefmJRIW7eWtXXahLpZRSx1UwLYr5QJkxZo8xpgd4Elh6DO8RBkSJSBgQDVQ565cCjzrPHwU+cwzHDI10Jx9rPyQyzM38wmTeLKsPbZmUUuo4CyYocoADAcsVzrq+zhaRjSLygojMBDDGVAIPAPuBaqDZGPOSs32GMaba2a4aSO/vzUXkRhEpEZGSuroQ//WePh3EBdUbAVhYlMqeunaqmjpDWy6llDqOggkK6Wed6bO8Acg3xswBfg78GcAZd1gKFALZQIyIfPFYCmiMecQYU2yMKU5LSzuWXUdfRLTtfqoqBeDcyakAvKWtCqXUKSyYoKgA8gKWc/mo+wgAY0yLMabNeb4aCBeRVOAiYK8xps4Y0ws8A5zj7FYjIlkAzmPtiGpyomSfDtWlYAzTMuNIjY3kjR06TqGUOnUFExTrgCIRKRSRCOxg9KrADUQkU0TEeT7fOW4DtsvpLBGJdl6/ENjm7LYKWO48Xw48N9LKnBBZc6G9DlqqEBGWzMzg1e01tHd7Q10ypZQ6LoYMCmOMF7gVeBH7Jb/SGLNVRG4WkZudza4GtojIRuBnwDJjvQc8je2a2uy83yPOPj8CFovILmCxs3zyy55rH6tLAbhiTjZdvX5e2VYTsiIppdTxJMb0HW44eRUXF5uSkpLQFqK3E36YB+fcChfdi99vOPe/XmN6VjwrvnRmaMumlFL9EJH1xpji4e6vM7OPVXiUbVXsfxcAl0u4Yk42a3fW0diuV5NVSp16NCiGY8JZULkeersAuGJuNl6/YfWW6hAXTCmlRp8GxXDknQW+niPjFDOy4pmUFsPKdQfw+8dOV55SSgVDg2I4JpxlH8v/DoCIcPN5k9hY0cyKv+8NYcGUUmr0aVAMR0wqpM+EPa8fWXX1GblcOC2d/355p15RVil1StGgGK5JF9gB7Z4OwLYqbr+oiI4eH89uqAxx4ZRSavRoUAzXpAvsOEX520dWnZabyJzcBB57t1zHKpRSpwwNiuGacA64I2HP345a/aVzCyirbePV7WPjiiRKKTUUDYrhioi2g9q7Xztq9adPyyYvOYoHX9ulrQql1ClBg2IkJn3S3hq19eCRVWFuF7d9soiNFc1857ktjKWZ70op1R8NipGYdIF9DDj7CeBzZ+Ryy/mT+ON7+/nJK7tOfLmUUmoUaVCMRMZsiE6FsleOWi0i/MuSqVx9Ri4/e3UXL2zWGdtKqbFLg2IkXC4ouhh2vQS+o+dOiAj/eeVs5uQm8K0/baJS74KnlBqjNChGatqnoKv5qNNkD4sIc/Gza06n12f4ro5XKKXGKA2KkZp0AYR5YPtf+305PyWGOxcX8cq2WpY98i6rNlZpYCilxhQNipGKiLHdT5tWQndbv5v8w7mF3HTeROrbuvnGEx9w/4s7TnAhlVJq+IIKChG5RER2iEiZiNzdz+vni0iziJQ6P/c466cGrCsVkRYRucN57V4RqQx47bJRrdmJdM5t0NUEHzzW78thbhf/eul0XrrzPK6al8Ov1u5hZ03riS2jUkoNU9hQG4iIG3gIe7vSCmCdiKwyxnzYZ9M3jTGXB64wxuwA5gYcpxJ4NmCTnxhjHhh+8U8SefPtTO13fgHzbwSXu9/N3C7hO5+awWvba7ntjx9w/tQ09ta3c9W8HC6ZlXWCC62UUsEJpkUxHygzxuwxxvQATwJLh/FeFwK7jTHlw9j35LfgRmje/7FTZftKjongoWvnsbehnV+t3cPGiiZu/sMG/rZDL/mhlDo5BRMUOcCBgOUKZ11fZ4vIRhF5QURm9vP6MuCJPutuFZFNIrJCRJL6e3MRuVFESkSkpK6uLojihsi0yyE2A9b9dshNz52cytM3n80zXz+H1++6gGmZcdzxZCmv76jlxa0Haev24vMbnlq3n5qWrhNQeKWUGpgMdQaOiHwOWGKM+aqzfD0w3xhzW8A28YDfGNPmjDX8jzGmKOD1CKAKmGmMqXHWZQD1gAH+A8gyxvzDYGUpLi42JSUlw6jmCfLa92HtA3DHJkicEPRuBw51sOyRd4/MtYiNDKO4IInXd9TZO+fddDYpsZHHq9RKqVOciKw3xhQPd/9gWhQVQF7Aci72S/8IY0yLMabNeb4aCBeR1IBNLgU2HA4JZ7saY4zPGOMHfo3t4hrb5i0HEVj/u2PaLS85mpU3n813PjWdR/9hPqdPSOT1HXV8clo6Bxo7+dTP3mLNlmoee2cfz5VWsrmimedKK/U0W6XUCTHkYDawDigSkULsYPQy4NrADUQkE6gxxhgRmY8NoIaATa6hT7eTiGQZYw5f2+JKYMvwqnASScyDoiU2KOYth6T8oHfNSYziqwsnArCoKJVNFc3MyklgW3ULdzxVys1/2HBk2zCX4PUbVry1lx6f4fGvLiA5JmLQ4/9w9Tbe33eIZ245BxEZVvWUUuPTkF1PAE530k8BN7DCGPMDEbkZwBjzsIjcCtwCeIFO4J+MMW87+0ZjxzgmGmOaA475GPaMKAPsA24KCI5+nfRdTwA1W+F/L4PIeLjl7+CJH/EhvT4/L31YQ5wnjBe3HqSmpZvC1Bhe2VZDeUMHV8/L5fNn5pEQFUZGvIcfvbCdM/KTuPL0HCoaO3l/7yHuenojxsDLdy6iKCNuFCqqlBorRtr1FFRQnCzGRFCAvUXqiiVw/v+D8791XN/qnue28Pt3PjqRzBPuoqvXD0CcJ4zWLi8AaXGR1LV2c8v5kzhnUgqfmJx6zC0Ln9+wubKZObkJI2qVGGO0VaPUCaRBcbJ68jrYuxZuWw+x6cftbdq6vfz5g0qyEjzUtnbz6rYarluQz6H2HkoPNJGTFMUZ+UlMSY/j2t+8y9aqFgCumT+B5JhwXtpaQ1VTJ0UZcdx18VS2VDUTGeai9EATHT0+7rioiHd2N7CgMIXVW6r55eu7+cGVszh/ajrPb6piQnIMCwqT+cO75Rxs6WJWTgKzcxKYlZPQb3m3VjXzj49v4NzJqdx7xUz21reTGhs5ZNeZUmr4NChOVnU74VcLIf8cuO5P9kqzIfbrtXv42au7WDglldWbDyIC50xKYXJaLG/srGNfQ8eRbV0C/d2gLyLMRYTbRVevD2+fDaIj3HT0+HAJ/Msl08hOjOL17bXMy0/is/Ny+Z9Xd7Hi73uJcLto6/YS7hZ6fYaEqHD+dMvZ1LR088f39/PlcwooLkgGbOujrLYNv4GJaTGEu+3vsa61m7rWbmZkf9S15/Mb3thZS3evn3OLUunq8bG+vJFpWfEUpsZwqL2H2tYupmXGU9/WzQtbDvKF4jwOtfdww4r3+Hxx3pFxIqVOJRoUJ7OSFfDXO2Hx9+Dc20NdGowx9PoMEWEuDjZ3EesJIzbSns/Q1NHDP6/cyLz8JObmJeIJd/PO7nre2dPAdz41g23VLeytb+e8KWncsOJ9Lp2VxTcunEx5Q4fTHZXIWROTqW7u4t5VW4/cMzw2Moy2bi+J0eE0dfRy1bwc7r50Gi9sPkh5QwdTMmJ54KUddHv99Pr8dHv9GAMLi1KZnB7Li1sOUtVs55JkJ3jITY4mNzGK9/Yeora1i5sWTWJbdQv5KTGUHmhkw/4mwHa7tXd78RuICnfzzxdP4fH39rOvoZ0bzspna1ULJeWNfPUThTS09/DsB5UATMuM4+sXTMYT5iLMLXxyWgYAvT4/7+05xOs7apmdm8C5k1Pp9vq56bESLp2VxdfPn3SkO+2xd/bx4N/KSIqO4LGvLCAtLpKuXh+rNlaxZGYmCVHhHGzuIjE6HE+4m4rGDupau4mPCqexvYeZ2QlERfQ/u/+wyqZOvvPsZpo6e3nia2fhCXfT2tVLnCd81P/dqLFPg+JkZgysvAF2rIZ/eAlyzwh1iUaF329wuQYeYzDGsKWyhfr2bhYVpfGXjVV8//kPuf2iKVx/1sfPBCurbeWnr+yirrWbBz43h79squIP79iurIVFaVw2O5Nwt4tnNlTS1u1lW3ULEW4XybERlDd0kJ3g4VBHD8nREdyxeAp5SdE88f5+JiRHs7AolR+/vJP39x7CE+5iycxM/rKxCr+B0yck8oETLDcumkhGvIdnNlQc6Z4DezZaS1fvkbGewJZWbGQYHT02jC6ansElszI51N7ND1/YzhkTkthS1cyktFgWz8hgfXkjb+6qZ3ZOAhdNz+DBv+2iICWGmdnx/GVTNb6A1lmYS5iWFUd2QhTnTEqhuCCZlz6s4bXtNTS293JmQRJv726gtctLZ6+Pm86bSE5iFPc8t5WsBA/zJiRx5+Ii0uM9VDZ2UpgagyfcTU1LF+/vPYQIzMiyLbG0uEjC3S484W721rdzyx/W4xLh7kunsWhKGgDv7mnghc3VzMtP4oo52YOOL61cd4D4qLCjLknT6/PzYVULpzljW80dvVz80ze4/cIpVDd3MjEthitPzz3qOAebu3hjZy1Xn5GHe5B/a4H/5lo6vSREfzwoy2pbyU6MwhPmRsTeK6a924vXb1uzgdq7vcREBnMy6NiiQXGy62yEhxfa6z/d+DpE9TsB/ZQ3nAHsgQKppqWLXp+fcLeLjQeauGh6xpDBtamimYgwF9Oz4qlu7qS8oYPTJySyqrQKY+CKudl4wt30eP38+KUdpMRG4BJhY0UzKTERJEVHMCEliktmZrGzppW3yur5YH8jNy6axLp9h3j4jd1HwmRmdjz/d/PZvLGjjn//y4ccbOnCJXZc6On1FXR7/Zw1MZkdB1vx+g1Xn5HLGflJtHd7SYqO4IMDTWypbObAoY4j3YEicGZBMulxkby49SAJUeH88WtnseKtvTy57gBulzA3L5HcpCje2FlHR7ePXr9tneUkRjEvP4kXtx6kx+v/2O9HxJa5uqkLA8R7wmjp8nLn4il09nj56Su76PH68foNl8zMpNvrY299OzGRYfznlbMJd7t4Y6e9asJ/rdlOVLib7y2dSXNnL186p4Dv/fVDfv9OOV9bWMjiGZm8v7eBB17aeaS16XYJj31lPvkpMfzvW3vZXNnM7rp26tu6+UJxHu09Xr66cCJz8xKpa+1mZckBqpo6KS5I4jNzcxARHnxtFz99ZRdXnp7Dh9UtnD4hkUtmZpGd6GHJT9eysCiNtm4vGMhM8LBqYxVJ0eG8/E/nYQys+Pte5hckc9Nj67l0diZfPCufti4vfy+rJzLcxbUL8olywvSMfPt/uL3byxPv7+ft3Q0snZvN0rlHX7CiqaOH1i4vecnRAPR4/WytamZKRtxRYdTt9VHb0s3OmlYy4j1UNXXy2vZarpqXy7MfVPKtS6aSGD2yMTwNirFg/3vwu8sgOgUu/gHMvtr+71SnjK5e+5/d5YLMeA9h7o/GpLq9Prq9fuI94bR1e2nr8pIRH4nXb/AbQ2TYwN1Me+vbWbf3EPMLkylIjQGgorGDCLeL9HgPvT4/D7y0gzd21PH7r8wnPc5DdXMnP3+tjPS4SHISo3j0nX00tvdy7uQUbji7gB6fnz117bgE6tu6ae3ysmF/I1HhYdxxURHhbheX//xNen32uyE5JoK/3vYJVry1lz+8V05BSgyT0mNZv6+R9h7vkYAEG0o1LV1Hxq8mpsWwp66dvOQoDhz66C6PWQkeqpu7yE7wEBHmYl9Dx5GWw6zseCLCXMR7wo90YUaEuTg9z7YAe3z+I2E2MTWGsyelHGkltnV7mZObwM6aNjp7fcRFhtHa/VH53C7BbwzXLZjAk+8fYOncHHp9flZttHOI4zw2vA5/LUa4XfiMIS02kswED5sqmnjh9kUcbOniX57eSE1LN6mxEdS39fCp07L49GnZVDV1suNgK3/dVEV7j4+pGXGI4IyRdRPhdnHD2fncsXgK6/Ye4ptPb6K+rRuw3aRul9hQc8zJS+Txry440k08HBoUY0Xlenj+n6HqAyhYCJ/+H0iZFOpSKdWvt3fX4xYhJTYST7iL3CT7V3Fgy3BLZTPLV7zPZbOzuO3CyWyrbmViagwvfVjD/oZ2ZuYk8OcPKsmM9/CDK2ezs6aV3XVtPP7efr79qen8dWM1501NY05uAr9/p5yuXh/XnZVPTmIUAB09Xv6ysYqzJ6byyzd2s6WymdMnJLL8nAIKU2J4ct0BXt1Ww9921OI3sOrWc8mI95AR76Gzx8dT6/bzny9s5+ZFE3m2tJLpmfH84wWT6ez1cdbEFH74wjZ+9cYeABZNSWNLZTM//vwcJiRHU9nYSXSEmymZceyubeOzv3wbv7FBkxobQU1LN1Mz4vjPq2YxJzeRh9/YzU9f2XUkIBOjwzl3cipTM+IoPdCES4Qwl7B4Rgbv7mng6Q0VpMbaU9anZcbxpXMKyEjw8J1nt3CovYebzpvIW7vq+czpOXx31VaK85N49B/m4wkffOxqIBoUY4nfBxsehVf+HSJibVdUbFqoS6XUsJ0Mc2LW7TvE3rp2Pn9m3sde6+zx4Ql30dnrwxPmPqqL0uc3PPtBJe/vbeC7n55JdIR7wLr85s09bKls5szCZH780k6+cGYe3/hk0VEnHRxs7qKhvZuMeA8pMRGD/l7e2d3At/+8mU9OTeeuJVOPBEBtaxfNHb1HTYp9rrSSO58q5RfXzRv27Qg0KMaiqlI7IS+pAD75bzDpkxARHepSKaVOUrvr2piUFjvs/U/ERQHVaMueC8v+CL0d8NR18OCZ0FwR6lIppU5SIwmJ0aBBESqTL4RbS+CaJ6G7BX67BNb8P2ivD3XJlFLqKBoUoRQWCVMvhWtX2oHt9x+BH0+D+ybBC9+Cruahj6GUUsfZqTezZCzKPxuWr4K6HfDBY9BSBet+AxUlsPjfIWsuRIa26amUGr80KE4maVPh4u/b59v+Cv+3HH73KQjzQFwWFC6EeV+yg+AxKaEsqVJqHNGgOFlNvxzu3AoHN8Oe16FpP5T+ETb8HjwJcNWvIWsO1G6z8zLc+lEqpY4P/XY5mcVl2p+ixXa5Ybe9MdLrP4Q/fh4QwEBsJkTEwEXfhWmfhqZySMjT8FBKjYqgvklE5BLgf7B3uPuNMeZHfV4/H3gO2OusesYY8z0RmQo8FbDpROAeY8xPRSTZea0Ae4e7zxtjGoddk/EgZZL9mXwRbP4/GwgpRbBzjQ2RlTeAuMH4IG8BXHgPRCXbW7RG6l3tlFLDM+SEOxFxAzuBxUAF9h7a1xhjPgzY5nzgLmPM5UMcpxJYYIwpF5H7gEPGmB+JyN1AkjFm0NvBnTIT7o4Hb7ftlmqusLO+33wAvPby3IgbkifawMiaCxh7RtXEC2zoHJ7sZ4wNn6jkUbmFq1Lq5DDSCXfBtCjmA2XGmD3OGz4JLAU+HHSvj7sQ2G2MOXzfzqXA+c7zR4HXgeN739BTWVgkzP/aR8tzr4X6nfbqtTVboWEX1JfB7p+AuCA82t4vwx1pu7c8CdBYDt3NEBEHxV+C2Z+HhFzw9UD9LttK8XV/vHXi67VhdBLcnEkpNfqCCYoc4EDAcgWwoJ/tzhaRjUAVtnWxtc/ry4AnApYzjDHVAMaYahHp936hInIjcCPAhAkTgiiuAiAhx/4AzLrqo/XGOD9+KP87lL0MrTXQ1QQ5Z0DmbLv+nYfg7Z8ffUxXGPi9kH8uVG+yM8tjUqHjkA2P3GLImw9FS6D1oG3RTPrk0af2Nuy2l1qPTj7uvwKl1OgIpuvpc8ASY8xXneXrgfnGmNsCtokH/MaYNhG5DPgfY0xRwOsR2ACZaYypcdY1GWMSA7ZpNMYMerMG7Xo6gRrLoWqD7crq7YTUIjuvQwS2/cW2LuJzoK3Wfum318PBTVCz5ejjhHkgYxbEZ9mWx8414I6A7HmQMcPOHelugbyz7JldTeVwxpcgPtseO3mibQGlTLKtn6gkCDvGa/Mf/jeul3ZX49SJ6HqqAAIvy5iL/dI/whjTEvB8tYj8QkRSjTGHr0dxKbDhcEg4akQky2lNZAG1w6uCOi6S8u1PoJlX2sfDcz36U7vdhkXiBNtlteMFqN5ou666W+0tYf0+e9n1zU9DTBrEpsPmlc7YSAKsuXvg4yfk2TGYzkOQVGhDJv8c26Lxe203m7fHhpAn0QbMe7+yXW0X3gP+XkidCu119hiN+2DShXYZIG3asQWRtwfW3gcTzrLjPUqdgoIJinVAkYgUYgejlwHXBm4gIplAjTHGiMh87KVBGgI2uYaju50AVgHLgR85j88Nqwbq5JI+zf4cVvCJgbc15uN/5Rtju6d6222I1O+yLYq67bZFsuVP9qyu1Pm2eysmDTattN1cxtiACIuCDY+B17lRTmS8HexfcfHQ5fck2u4zsC0pd4Ttwsuaa1tMzZWQMhn2vw0zlsKuV+xzVxic+VU7MTIq0W7X2wEL/9mGX0sV9Dh1Mj7Y95adB/P2z21oFiyEKUucbrkU2PemDZ6YVFuvjkP2uK7h3Y9AqZEI6jLjTnfST7Gnx64wxvxARG4GMMY8LCK3ArcAXqAT+CdjzNvOvtHYMY6JxpjmgGOmACuBCcB+4HPGmEODlUO7nlTQDo/DHHjftow6GmxrJyLGtiLiMm2AxKRA2at2tjtA2StwcIsNsIgYG051O6Cn1X7hx6RBQ5ntEju0ByITYPG9diZ9+d8DzjRzAQLucFsOX8/Hy3j4VObcM+2l5/29H+1r/LarbdInYf87dgzJk2DLmVRoA6S7zZbR+Oz+M66wJyCUv23n0Pj9Niy93RCbAdmn2/o1H4Azv2Z/D8b30e/K5bZdgofPgvP7nHpguxZF7PuqMUfvR6HU8dbTAW01kJhvz+zqabddWXvfsK2Cw/dBN8a+1tVsv2wb99nWjjvcBktErO3iMgbSpsDaH9sv7yU/sOMxddvsPg1lUHQxbH0Wtj9vTx7IOcOeudZS5YzrtNqTBDoa7ZloGTPt3RNHKiLWduN1tdhWnSfRBkhHAyCQPsPWISLG1jUu09YtIde2jLpbbZgePlMuzGPPxus8ZFt61aW2qzE2w/7eUopsl6EnwbbKtj4LlSV2v3k32C7Mht22TG0HIWGCDUtPvH2PyDj7WXQ22d9H/U7bIutshPSZNjB9vfbYb//chvGCW8bd/V80KJQaz3y9tsUQGWtbFdv/CpMX2y9SV5g9bTrMY08UqNxgv6RjUm2rI/t027UmLtta6Gm3Jxv4emxLKTIOWqttyyJztg2Iqg32JIbeDhsqLVW2ZdVUbsd+kvJtqLrCbAhUfQC1Wz9qJSVPsl/inY1AP9897gjbwmqusMccirht/XrbPzor77DYjI9akLGZ0OoMrUanQOoU23WZOsV2LbbX2/pXrrfjVDnzbBniMu1xuprsHwopk+1JHYf22NbY9udh1mftOFlOMVS8Dy2VEJdtw7u1Gmo/hIzZNgz3v2N/D9v+AgXnQuZpdvnwT3SqDbHORvu76m61J4ukThnRyRgaFEqp0OtvvAlskDUfsF+yPe0fTeT0+2wroPZDGw4tlXbdlIvtF6rPa7+0Oxrsl3NPK8Sk2y/9Nud0ble4Xe5qhuRCG2RZc+0JDu5I2PWSfa/ECfYLOm8BTPsUvPOgDbiEXNvqaamyAeqOtIFYt92eFBGbYd/L123D6HC3ImJbTV3NMPE823VpfMf2+0qdYluOxh/c9vG58Jlf2PcbhhNx1pNSSg1uoL92D3e7wdGz/V1uOz5UuHCA/cJgQj/TtRI/fl/sAc29pv/1E84aet/DwdfdZkPAkwB1O6Glwo7jRCXaMSCXy55o0FYDu/9mT+TIPxeaDkDNZhs++WdDzYe266xgkQ2e+BwbbN2t9n3EZX+aK2xXZ1SibQV6EmyI7njh2Oo+yrRFoZRSpzi9Z7ZSSqnjSoNCKaXUoDQolFJKDUqDQiml1KA0KJRSSg1Kg0IppdSgNCiUUkoNSoNCKaXUoMbUhDsRqQOCuAAMqUD9kFuNPVqvsUXrNfacqnWbaoyJG3qz/o2pS3gYY9KC2U5ESkYyC/FkpfUaW7ReY8+pWjcRGdElLbTrSSml1KA0KJRSSg3qVA2KR0JdgONE6zW2aL3GnlO1biOq15gazFZKKXXinaotCqWUUqNEg0IppdSgTqmgEJFLRGSHiJSJyN2hLs9IiMg+EdksIqWHT20TkWQReVlEdjmPSaEuZzBEZIWI1IrIloB1A9ZFRP7V+Qx3iMiS0JR6aAPU614RqXQ+t1IRuSzgtbFSrzwR+ZuIbBORrSJyu7N+TH9mg9RrTH9mIuIRkfdFZKNTr3931o/e52WMOSV+ADewG5gIRAAbgRmhLtcI6rMPSO2z7j7gbuf53cB/hbqcQdZlETAP2DJUXYAZzmcXCRQ6n6k71HU4hnrdC9zVz7ZjqV5ZwDzneRyw0yn/mP7MBqnXmP7MAAFinefhwHvAWaP5eZ1KLYr5QJkxZo8xpgd4Elga4jKNtqXAo87zR4HPhK4owTPGrAUO9Vk9UF2WAk8aY7qNMXuBMuxne9IZoF4DGUv1qjbGbHCetwLbgBzG+Gc2SL0GMlbqZYwxbc5iuPNjGMXP61QKihzgQMByBYP/IzjZGeAlEVkvIjc66zKMMdVg/9ED6SEr3cgNVJdT4XO8VUQ2OV1Th5v7Y7JeIlIAnI79K/WU+cz61AvG+GcmIm4RKQVqgZeNMaP6eZ1KQSH9rBvL5/6ea4yZB1wK/KOILAp1gU6Qsf45/hKYBMwFqoEfO+vHXL1EJBb4E3CHMaZlsE37WXfS1q2feo35z8wY4zPGzAVygfkiMmuQzY+5XqdSUFQAeQHLuUBViMoyYsaYKuexFngW2zSsEZEsAOexNnQlHLGB6jKmP0djTI3zn9YP/JqPmvRjql4iEo79Mn3cGPOMs3rMf2b91etU+cwAjDFNwOvAJYzi53UqBcU6oEhECkUkAlgGrApxmYZFRGJEJO7wc+BiYAu2PsudzZYDz4WmhKNioLqsApaJSKSIFAJFwPshKN+wHP6P6bgS+7nBGKqXiAjwW2CbMea/A14a05/ZQPUa65+ZiKSJSKLzPAq4CNjOaH5eoR6xH+XR/8uwZzLsBr4d6vKMoB4TsWclbAS2Hq4LkAK8CuxyHpNDXdYg6/MEtknfi/1r5iuD1QX4tvMZ7gAuDXX5j7FejwGbgU3Of8isMVivT2C7IjYBpc7PZWP9MxukXmP6MwNOAz5wyr8FuMdZP2qfl17CQyml1KBOpa4npZRSx4EGhVJKqUFpUCillBqUBoVSSqlBaVAopZQalAaFUkqpQWlQKKWUGtT/BynFk39MgV7XAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, [\"loss\", \"val_loss\"]].plot()\n",
    "history_df.loc[5:, [\"auc\", \"val_auc\"]].plot()\n",
    "\n",
    "print(\n",
    "    (\"Best Validation Loss: {:0.6f}\" + \"\\nBest Validation AUC: {:0.6f}\").format(\n",
    "        history_df[\"val_loss\"].min(), history_df[\"val_auc\"].max()\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# SGD:\n",
    "# Best Validation Loss: 0.565582\n",
    "# Best Validation Accuracy: 0.750882\n",
    "\n",
    "# ADAM:\n",
    "# 06 Clusters PF-Degree 2: 0.755635\n",
    "# 08 Clusters PF-Degree 2: 0.755701\n",
    "# 08 Clusters PF-Degree 3: 0.754991\n",
    "# 09 Clusters PF-Degree 2: 0.755704 \n",
    "# 09 Clusters PF-Degree 2: 0.755857 ** (learning rate = 0.0001)\n",
    "# 10 Clusters PF-Degree 2: 0.755059\n",
    "\n",
    "# 09 Clusters PF-Degree 2: OPT: 0.756616 | Kaggle: 0.74796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| best_score: 0.7544742822647095\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_score = history_df[\"val_auc\"].max()\n",
    "ic(best_score)\n",
    "\n",
    "message = f'New baseline score: {best_score}'\n",
    "send_telegram_message(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-12_submission_DL-2layer-FE-opt.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#mlflow_run_id = str(run.info.run_id)\n",
    "objective = \"DL-2layer-FE-opt\"\n",
    "\n",
    "curr_submission_fn = f\"{now}_submission_{objective}.csv\"\n",
    "\n",
    "sample_df['target'] = preds_test\n",
    "sample_df.to_csv(PATH_SUB + curr_submission_fn, index=False)\n",
    "\n",
    "print(curr_submission_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539995</th>\n",
       "      <td>1139995</td>\n",
       "      <td>0.754018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539996</th>\n",
       "      <td>1139996</td>\n",
       "      <td>0.730101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539997</th>\n",
       "      <td>1139997</td>\n",
       "      <td>0.635519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539998</th>\n",
       "      <td>1139998</td>\n",
       "      <td>0.733412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539999</th>\n",
       "      <td>1139999</td>\n",
       "      <td>0.724752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    target\n",
       "539995  1139995  0.754018\n",
       "539996  1139996  0.730101\n",
       "539997  1139997  0.635519\n",
       "539998  1139998  0.733412\n",
       "539999  1139999  0.724752"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit tabular-playground-series-nov-2021 -f {PATH_SUB+curr_submission_fn} -m {curr_submission_fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningapplied.com/hyperparameter-search-with-optuna-part-3-keras-cnn-classification-and-ensembling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing new Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.backend import clear_session\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nn = X.copy()\n",
    "X_test_nn = X_test.copy()\n",
    "# X_nn[\"linear_preds\"] = linear_oof_preds\n",
    "# X_test_nn[\"linear_preds\"] = linear_test_preds\n",
    "# Scaling all values\n",
    "mm_scaler = MinMaxScaler()\n",
    "for col in X_nn.columns:\n",
    "    X_nn[col] = mm_scaler.fit_transform(np.array(X_nn[col]).reshape(-1,1))\n",
    "    X_test_nn[col] = mm_scaler.transform(np.array(X_test_nn[col]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_poly37</th>\n",
       "      <th>cluster_poly38</th>\n",
       "      <th>cluster_poly39</th>\n",
       "      <th>cluster_poly40</th>\n",
       "      <th>cluster_poly41</th>\n",
       "      <th>cluster_poly42</th>\n",
       "      <th>cluster_poly43</th>\n",
       "      <th>cluster_poly44</th>\n",
       "      <th>cluster_poly45</th>\n",
       "      <th>cluster_poly46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310367</td>\n",
       "      <td>0.646697</td>\n",
       "      <td>0.248101</td>\n",
       "      <td>0.577060</td>\n",
       "      <td>0.286635</td>\n",
       "      <td>0.306885</td>\n",
       "      <td>0.626685</td>\n",
       "      <td>0.470543</td>\n",
       "      <td>0.437860</td>\n",
       "      <td>0.268236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.030110</td>\n",
       "      <td>0.015879</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.032175</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>0.015516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311828</td>\n",
       "      <td>0.388867</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.601646</td>\n",
       "      <td>0.288154</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>0.305376</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>0.758411</td>\n",
       "      <td>0.270864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>0.007375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304777</td>\n",
       "      <td>0.365259</td>\n",
       "      <td>0.260754</td>\n",
       "      <td>0.451589</td>\n",
       "      <td>0.281835</td>\n",
       "      <td>0.559115</td>\n",
       "      <td>0.799909</td>\n",
       "      <td>0.680494</td>\n",
       "      <td>0.398849</td>\n",
       "      <td>0.272862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.004281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300770</td>\n",
       "      <td>0.197292</td>\n",
       "      <td>0.329385</td>\n",
       "      <td>0.413095</td>\n",
       "      <td>0.280095</td>\n",
       "      <td>0.351457</td>\n",
       "      <td>0.491403</td>\n",
       "      <td>0.769063</td>\n",
       "      <td>0.752827</td>\n",
       "      <td>0.279748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.024605</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.042691</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>0.024612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.301630</td>\n",
       "      <td>0.662944</td>\n",
       "      <td>0.251031</td>\n",
       "      <td>0.445679</td>\n",
       "      <td>0.281083</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.681947</td>\n",
       "      <td>0.164935</td>\n",
       "      <td>0.604515</td>\n",
       "      <td>0.270498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0.003776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.310367  0.646697  0.248101  0.577060  0.286635  0.306885  0.626685   \n",
       "1  0.311828  0.388867  0.241034  0.601646  0.288154  0.815037  0.305376   \n",
       "2  0.304777  0.365259  0.260754  0.451589  0.281835  0.559115  0.799909   \n",
       "3  0.300770  0.197292  0.329385  0.413095  0.280095  0.351457  0.491403   \n",
       "4  0.301630  0.662944  0.251031  0.445679  0.281083  0.425300  0.681947   \n",
       "\n",
       "         f7        f8        f9  ...  cluster_poly37  cluster_poly38  \\\n",
       "0  0.470543  0.437860  0.268236  ...        0.014472        0.029369   \n",
       "1  0.107503  0.758411  0.270864  ...        0.006808        0.018038   \n",
       "2  0.680494  0.398849  0.272862  ...        0.003574        0.011991   \n",
       "3  0.769063  0.752827  0.279748  ...        0.024383        0.043712   \n",
       "4  0.164935  0.604515  0.270498  ...        0.003871        0.012480   \n",
       "\n",
       "   cluster_poly39  cluster_poly40  cluster_poly41  cluster_poly42  \\\n",
       "0        0.015020        0.014219        0.030110        0.015879   \n",
       "1        0.007292        0.007050        0.015973        0.007210   \n",
       "2        0.004124        0.003888        0.009477        0.004007   \n",
       "3        0.024605        0.024456        0.042691        0.024659   \n",
       "4        0.003815        0.003873        0.010492        0.003882   \n",
       "\n",
       "   cluster_poly43  cluster_poly44  cluster_poly45  cluster_poly46  \n",
       "0        0.015047        0.032175        0.028565        0.015516  \n",
       "1        0.007002        0.018852        0.016215        0.007375  \n",
       "2        0.003828        0.013541        0.010429        0.004281  \n",
       "3        0.024506        0.043213        0.041747        0.024612  \n",
       "4        0.003960        0.012174        0.010219        0.003776  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0121662381829593, 1: 0.9881227643722456}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "class_weights_dict={}\n",
    "for label in np.sort(y.unique()):\n",
    "    class_weights_dict[label] = class_weights[label]\n",
    "    \n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear clutter from previous Keras session graphs.\n",
    "clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model():\n",
    "    \"\"\"\n",
    "    Builds and returns a sequential NN model along with its callbacks.\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    # An input layer\n",
    "    model.add(keras.layers.Input(shape=[X.shape[1],]))\n",
    "    # Hidden layers\n",
    "    model.add(keras.layers.Dense(64, kernel_initializer=keras.initializers.GlorotNormal, activation=\"swish\")) #64\n",
    "    keras.layers.Dropout(0.2),\n",
    "    model.add(keras.layers.Dense(32, kernel_initializer=keras.initializers.GlorotNormal, activation=\"swish\"))\n",
    "    keras.layers.Dropout(0.2),\n",
    "    model.add(keras.layers.Dense(16, kernel_initializer=keras.initializers.GlorotNormal, activation=\"swish\"))\n",
    "    keras.layers.Dropout(0.2),\n",
    "    model.add(keras.layers.Dense(8, kernel_initializer=keras.initializers.GlorotNormal, activation=\"swish\"))\n",
    "    keras.layers.Dropout(0.2),\n",
    "    #model.add(keras.layers.Dense(4, kernel_initializer=keras.initializers.GlorotNormal, activation=\"swish\"))\n",
    "    #keras.layers.Dropout(0.2),\n",
    "    # An output layer\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Checking layers setup\n",
    "    model.summary()\n",
    "\n",
    "    # A callback to stop training when overfitting is detected\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "    # A callback to reduce learning rate when plateau is detected\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_auc', factor=0.2, patience=5, verbose=0,\n",
    "                min_lr=0.00001, mode='min')\n",
    "\n",
    "    # Compiling a model\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=0.001), #0.001\n",
    "                  metrics=['AUC', 'FalsePositives', 'FalseNegatives', 'BinaryAccuracy']\n",
    "                 )\n",
    "    return model, early_stopping_cb, reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Training with fold 0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                9984      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,737\n",
      "Trainable params: 12,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "15000/15000 [==============================] - 122s 8ms/step - loss: 0.6045 - auc: 0.7306 - false_positives: 74273.0000 - false_negatives: 72592.0000 - binary_accuracy: 0.6940 - val_loss: 0.5895 - val_auc: 0.7416 - val_false_positives: 16780.0000 - val_false_negatives: 17347.0000 - val_binary_accuracy: 0.7156 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5920 - auc: 0.7403 - false_positives: 70262.0000 - false_negatives: 68541.0000 - binary_accuracy: 0.7108 - val_loss: 0.5932 - val_auc: 0.7450 - val_false_positives: 22246.0000 - val_false_negatives: 12732.0000 - val_binary_accuracy: 0.7085 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "15000/15000 [==============================] - 120s 8ms/step - loss: 0.5886 - auc: 0.7427 - false_positives: 69228.0000 - false_negatives: 67412.0000 - binary_accuracy: 0.7153 - val_loss: 0.5838 - val_auc: 0.7465 - val_false_positives: 15483.0000 - val_false_negatives: 17617.0000 - val_binary_accuracy: 0.7242 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "15000/15000 [==============================] - 120s 8ms/step - loss: 0.5854 - auc: 0.7450 - false_positives: 68583.0000 - false_negatives: 66044.0000 - binary_accuracy: 0.7195 - val_loss: 0.5835 - val_auc: 0.7482 - val_false_positives: 19434.0000 - val_false_negatives: 13772.0000 - val_binary_accuracy: 0.7233 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5836 - auc: 0.7463 - false_positives: 67966.0000 - false_negatives: 65393.0000 - binary_accuracy: 0.7222 - val_loss: 0.5795 - val_auc: 0.7484 - val_false_positives: 17521.0000 - val_false_negatives: 14809.0000 - val_binary_accuracy: 0.7306 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5825 - auc: 0.7471 - false_positives: 67673.0000 - false_negatives: 64881.0000 - binary_accuracy: 0.7238 - val_loss: 0.5866 - val_auc: 0.7488 - val_false_positives: 20970.0000 - val_false_negatives: 12964.0000 - val_binary_accuracy: 0.7172 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5744 - auc: 0.7523 - false_positives: 65320.0000 - false_negatives: 62292.0000 - binary_accuracy: 0.7341 - val_loss: 0.5733 - val_auc: 0.7516 - val_false_positives: 15612.0000 - val_false_negatives: 16063.0000 - val_binary_accuracy: 0.7360 - lr: 2.0000e-04\n",
      "Epoch 8/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5732 - auc: 0.7532 - false_positives: 64989.0000 - false_negatives: 61852.0000 - binary_accuracy: 0.7357 - val_loss: 0.5726 - val_auc: 0.7516 - val_false_positives: 15521.0000 - val_false_negatives: 16023.0000 - val_binary_accuracy: 0.7371 - lr: 2.0000e-04\n",
      "Epoch 9/30\n",
      "15000/15000 [==============================] - 120s 8ms/step - loss: 0.5726 - auc: 0.7538 - false_positives: 64805.0000 - false_negatives: 61761.0000 - binary_accuracy: 0.7363 - val_loss: 0.5734 - val_auc: 0.7514 - val_false_positives: 17510.0000 - val_false_negatives: 14194.0000 - val_binary_accuracy: 0.7358 - lr: 2.0000e-04\n",
      "Epoch 10/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5722 - auc: 0.7538 - false_positives: 64578.0000 - false_negatives: 61677.0000 - binary_accuracy: 0.7370 - val_loss: 0.5721 - val_auc: 0.7519 - val_false_positives: 17101.0000 - val_false_negatives: 14384.0000 - val_binary_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 11/30\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.5716 - auc: 0.7541 - false_positives: 64383.0000 - false_negatives: 61561.0000 - binary_accuracy: 0.7376 - val_loss: 0.5707 - val_auc: 0.7525 - val_false_positives: 16454.0000 - val_false_negatives: 14837.0000 - val_binary_accuracy: 0.7392 - lr: 2.0000e-04\n",
      "Epoch 12/30\n",
      "12945/15000 [========================>.....] - ETA: 14s - loss: 0.5694 - auc: 0.7555 - false_positives: 55040.0000 - false_negatives: 52390.0000 - binary_accuracy: 0.7407"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7948/4055800183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_nn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     history = nn_model.fit(X_train, y_train, epochs=30,\n\u001b[0m\u001b[0;32m     20\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fold splitting parameters\n",
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Two zero-filled arrays for out-of-fold and test predictions\n",
    "nn_oof_preds = np.zeros((X_nn.shape[0],))\n",
    "nn_test_preds = np.zeros((X_test_nn.shape[0],))\n",
    "total_mean_auc = 0\n",
    "\n",
    "# Generating folds and making training and prediction for each of them\n",
    "for num, (train_idx, valid_idx) in enumerate(skf.split(X_nn, y)):\n",
    "    clear_session()\n",
    "    gc.collect()\n",
    "    print(f\"\\n===Training with fold {num}\")\n",
    "    X_train, X_valid = X_nn.loc[train_idx], X_nn.loc[valid_idx]\n",
    "    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "    nn_model, early_stopping_cb, reduce_lr = get_nn_model()\n",
    "    history = nn_model.fit(X_train, y_train, epochs=30,\n",
    "                            validation_data=(X_valid, y_valid), \n",
    "                            callbacks=[early_stopping_cb, reduce_lr],\n",
    "                            class_weight=class_weights_dict\n",
    "                           )\n",
    "    \n",
    "    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n",
    "    # So in the end it will be completely filled with unseen data predictions.\n",
    "    # It will be used to evaluate hyperparameters performance only.    \n",
    "    nn_oof_preds[valid_idx] = nn_model.predict(X_valid).flatten()\n",
    "    \n",
    "    # Getting mean test data predictions (i.e. devided by number of splits)\n",
    "    nn_test_preds += nn_model.predict(X_test_nn).flatten() / splits\n",
    "    \n",
    "    # Getting score for a fold model\n",
    "    fold_auc = roc_auc_score(y_valid, nn_oof_preds[valid_idx])\n",
    "    print(f\"\\n=== Fold {num} ROC AUC: {fold_auc} ===\")\n",
    "    \n",
    "    # Getting mean score of all fold models (i.e. devided by number of splits)\n",
    "    total_mean_auc += fold_auc / splits\n",
    "\n",
    "print(f\"\\nOverall ROC AUC: {total_mean_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "- 5 layers: 64, 32, 8,4 AUC: 0.7536374249876355 | 0.74771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.741963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.738693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.747105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.363046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.709745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  600000  0.741963\n",
       "1  600001  0.738693\n",
       "2  600002  0.747105\n",
       "3  600003  0.363046\n",
       "4  600004  0.709745"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions[\"id\"] = test_df[\"id\"].astype(int)\n",
    "predictions[\"target\"] = nn_test_preds\n",
    "\n",
    "predictions.to_csv('submission.csv', index=False, header=predictions.columns)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74196276, 0.73869251, 0.74710482, ..., 0.72205471, 0.73356397,\n",
       "       0.7455571 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Tabular Playground Series - Nov 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/14.2M [00:00<?, ?B/s]\n",
      "  1%|          | 80.0k/14.2M [00:00<00:20, 729kB/s]\n",
      "  1%|▏         | 184k/14.2M [00:00<00:17, 838kB/s] \n",
      "  2%|▏         | 272k/14.2M [00:00<00:27, 528kB/s]\n",
      "  2%|▏         | 336k/14.2M [00:00<00:30, 477kB/s]\n",
      "  3%|▎         | 392k/14.2M [00:00<00:33, 436kB/s]\n",
      "  3%|▎         | 440k/14.2M [00:00<00:36, 391kB/s]\n",
      "  3%|▎         | 488k/14.2M [00:01<00:36, 395kB/s]\n",
      "  4%|▎         | 528k/14.2M [00:01<00:36, 389kB/s]\n",
      "  4%|▍         | 568k/14.2M [00:01<00:37, 383kB/s]\n",
      "  4%|▍         | 608k/14.2M [00:01<00:37, 380kB/s]\n",
      "  4%|▍         | 648k/14.2M [00:01<00:37, 376kB/s]\n",
      "  5%|▍         | 688k/14.2M [00:01<00:38, 371kB/s]\n",
      "  5%|▌         | 728k/14.2M [00:01<00:37, 371kB/s]\n",
      "  5%|▌         | 768k/14.2M [00:02<01:23, 169kB/s]\n",
      "  6%|▋         | 920k/14.2M [00:02<00:37, 370kB/s]\n",
      "  7%|▋         | 984k/14.2M [00:02<00:37, 371kB/s]\n",
      "  7%|▋         | 1.02M/14.2M [00:02<00:36, 374kB/s]\n",
      "  8%|▊         | 1.07M/14.2M [00:02<00:37, 366kB/s]\n",
      "  8%|▊         | 1.12M/14.2M [00:03<00:37, 364kB/s]\n",
      "  8%|▊         | 1.16M/14.2M [00:03<00:37, 368kB/s]\n",
      "  9%|▊         | 1.21M/14.2M [00:03<00:37, 362kB/s]\n",
      "  9%|▉         | 1.25M/14.2M [00:03<00:37, 360kB/s]\n",
      "  9%|▉         | 1.29M/14.2M [00:03<00:38, 352kB/s]\n",
      "  9%|▉         | 1.34M/14.2M [00:03<00:36, 370kB/s]\n",
      " 10%|▉         | 1.38M/14.2M [00:03<00:36, 367kB/s]\n",
      " 10%|▉         | 1.41M/14.2M [00:03<00:36, 363kB/s]\n",
      " 10%|█         | 1.45M/14.2M [00:04<00:35, 375kB/s]\n",
      " 11%|█         | 1.49M/14.2M [00:04<00:36, 364kB/s]\n",
      " 11%|█         | 1.53M/14.2M [00:04<00:36, 366kB/s]\n",
      " 11%|█         | 1.57M/14.2M [00:04<00:36, 366kB/s]\n",
      " 11%|█▏        | 1.61M/14.2M [00:04<00:36, 359kB/s]\n",
      " 12%|█▏        | 1.65M/14.2M [00:04<00:36, 357kB/s]\n",
      " 12%|█▏        | 1.69M/14.2M [00:04<00:36, 361kB/s]\n",
      " 12%|█▏        | 1.73M/14.2M [00:04<00:36, 358kB/s]\n",
      " 13%|█▎        | 1.77M/14.2M [00:04<00:35, 370kB/s]\n",
      " 13%|█▎        | 1.81M/14.2M [00:05<00:35, 360kB/s]\n",
      " 13%|█▎        | 1.86M/14.2M [00:05<00:34, 371kB/s]\n",
      " 13%|█▎        | 1.90M/14.2M [00:05<00:34, 368kB/s]\n",
      " 14%|█▎        | 1.94M/14.2M [00:05<00:34, 369kB/s]\n",
      " 14%|█▍        | 1.98M/14.2M [00:05<00:35, 363kB/s]\n",
      " 14%|█▍        | 2.02M/14.2M [00:05<00:34, 369kB/s]\n",
      " 15%|█▍        | 2.05M/14.2M [00:05<00:34, 369kB/s]\n",
      " 15%|█▍        | 2.09M/14.2M [00:05<00:34, 371kB/s]\n",
      " 15%|█▌        | 2.13M/14.2M [00:05<00:34, 363kB/s]\n",
      " 15%|█▌        | 2.17M/14.2M [00:06<00:36, 347kB/s]\n",
      " 16%|█▌        | 2.21M/14.2M [00:06<00:35, 354kB/s]\n",
      " 16%|█▌        | 2.25M/14.2M [00:06<00:34, 359kB/s]\n",
      " 16%|█▌        | 2.29M/14.2M [00:06<00:34, 360kB/s]\n",
      " 16%|█▋        | 2.33M/14.2M [00:06<00:36, 342kB/s]\n",
      " 17%|█▋        | 2.37M/14.2M [00:06<00:35, 353kB/s]\n",
      " 17%|█▋        | 2.41M/14.2M [00:06<00:34, 353kB/s]\n",
      " 17%|█▋        | 2.45M/14.2M [00:06<00:34, 353kB/s]\n",
      " 18%|█▊        | 2.48M/14.2M [00:07<00:35, 345kB/s]\n",
      " 18%|█▊        | 2.52M/14.2M [00:07<00:35, 339kB/s]\n",
      " 18%|█▊        | 2.56M/14.2M [00:07<00:34, 348kB/s]\n",
      " 18%|█▊        | 2.60M/14.2M [00:07<00:35, 340kB/s]\n",
      " 19%|█▊        | 2.64M/14.2M [00:07<00:35, 339kB/s]\n",
      " 19%|█▉        | 2.68M/14.2M [00:07<00:34, 349kB/s]\n",
      " 19%|█▉        | 2.72M/14.2M [00:07<00:33, 360kB/s]\n",
      " 19%|█▉        | 2.76M/14.2M [00:07<00:33, 359kB/s]\n",
      " 20%|█▉        | 2.80M/14.2M [00:07<00:33, 357kB/s]\n",
      " 20%|██        | 2.84M/14.2M [00:08<00:32, 361kB/s]\n",
      " 20%|██        | 2.88M/14.2M [00:08<00:32, 361kB/s]\n",
      " 21%|██        | 2.91M/14.2M [00:08<00:32, 359kB/s]\n",
      " 21%|██        | 2.95M/14.2M [00:08<00:32, 363kB/s]\n",
      " 21%|██        | 2.99M/14.2M [00:08<00:33, 353kB/s]\n",
      " 21%|██▏       | 3.03M/14.2M [00:08<00:32, 362kB/s]\n",
      " 22%|██▏       | 3.07M/14.2M [00:08<00:31, 366kB/s]\n",
      " 22%|██▏       | 3.11M/14.2M [00:08<00:31, 367kB/s]\n",
      " 22%|██▏       | 3.15M/14.2M [00:08<00:32, 358kB/s]\n",
      " 23%|██▎       | 3.19M/14.2M [00:09<00:31, 362kB/s]\n",
      " 23%|██▎       | 3.23M/14.2M [00:09<00:32, 356kB/s]\n",
      " 23%|██▎       | 3.27M/14.2M [00:09<00:32, 353kB/s]\n",
      " 23%|██▎       | 3.30M/14.2M [00:09<00:31, 363kB/s]\n",
      " 24%|██▎       | 3.34M/14.2M [00:09<00:31, 360kB/s]\n",
      " 25%|██▍       | 3.51M/14.2M [00:09<00:16, 696kB/s]\n",
      " 25%|██▌       | 3.58M/14.2M [00:09<00:19, 566kB/s]\n",
      " 26%|██▌       | 3.64M/14.2M [00:10<00:22, 496kB/s]\n",
      " 26%|██▌       | 3.70M/14.2M [00:10<00:24, 456kB/s]\n",
      " 26%|██▋       | 3.74M/14.2M [00:10<00:25, 435kB/s]\n",
      " 27%|██▋       | 3.79M/14.2M [00:10<00:26, 412kB/s]\n",
      " 27%|██▋       | 3.84M/14.2M [00:10<00:26, 401kB/s]\n",
      " 27%|██▋       | 3.88M/14.2M [00:10<00:27, 395kB/s]\n",
      " 28%|██▊       | 3.91M/14.2M [00:10<00:28, 380kB/s]\n",
      " 28%|██▊       | 3.95M/14.2M [00:10<00:29, 368kB/s]\n",
      " 28%|██▊       | 3.99M/14.2M [00:11<00:29, 359kB/s]\n",
      " 28%|██▊       | 4.03M/14.2M [00:11<00:29, 355kB/s]\n",
      " 29%|██▊       | 4.07M/14.2M [00:11<00:30, 352kB/s]\n",
      " 29%|██▉       | 4.11M/14.2M [00:11<01:04, 163kB/s]\n",
      " 30%|███       | 4.30M/14.2M [00:12<00:24, 423kB/s]\n",
      " 31%|███       | 4.38M/14.2M [00:12<00:34, 297kB/s]\n",
      " 31%|███▏      | 4.45M/14.2M [00:12<00:29, 346kB/s]\n",
      " 32%|███▏      | 4.52M/14.2M [00:12<00:25, 403kB/s]\n",
      " 32%|███▏      | 4.59M/14.2M [00:12<00:26, 373kB/s]\n",
      " 33%|███▎      | 4.64M/14.2M [00:13<00:30, 326kB/s]\n",
      " 33%|███▎      | 4.69M/14.2M [00:13<00:31, 314kB/s]\n",
      " 33%|███▎      | 4.73M/14.2M [00:13<00:32, 309kB/s]\n",
      " 34%|███▎      | 4.77M/14.2M [00:13<00:32, 302kB/s]\n",
      " 34%|███▍      | 4.80M/14.2M [00:13<00:30, 317kB/s]\n",
      " 34%|███▍      | 4.84M/14.2M [00:13<00:30, 320kB/s]\n",
      " 34%|███▍      | 4.88M/14.2M [00:13<00:30, 319kB/s]\n",
      " 35%|███▍      | 4.92M/14.2M [00:14<00:29, 325kB/s]\n",
      " 35%|███▌      | 4.96M/14.2M [00:14<00:32, 297kB/s]\n",
      " 35%|███▌      | 4.99M/14.2M [00:14<00:32, 292kB/s]\n",
      " 35%|███▌      | 5.02M/14.2M [00:14<00:32, 297kB/s]\n",
      " 36%|███▌      | 5.05M/14.2M [00:14<00:33, 286kB/s]\n",
      " 36%|███▌      | 5.09M/14.2M [00:14<00:32, 296kB/s]\n",
      " 36%|███▌      | 5.12M/14.2M [00:14<00:31, 304kB/s]\n",
      " 36%|███▋      | 5.16M/14.2M [00:14<00:29, 318kB/s]\n",
      " 37%|███▋      | 5.20M/14.2M [00:15<00:29, 316kB/s]\n",
      " 37%|███▋      | 5.23M/14.2M [00:15<00:29, 316kB/s]\n",
      " 37%|███▋      | 5.27M/14.2M [00:15<00:29, 312kB/s]\n",
      " 37%|███▋      | 5.30M/14.2M [00:15<00:30, 303kB/s]\n",
      " 38%|███▊      | 5.33M/14.2M [00:15<00:29, 309kB/s]\n",
      " 38%|███▊      | 5.36M/14.2M [00:15<00:30, 299kB/s]\n",
      " 38%|███▊      | 5.39M/14.2M [00:15<00:30, 306kB/s]\n",
      " 38%|███▊      | 5.43M/14.2M [00:15<00:28, 320kB/s]\n",
      " 39%|███▊      | 5.46M/14.2M [00:15<00:29, 312kB/s]\n",
      " 39%|███▉      | 5.50M/14.2M [00:16<00:27, 332kB/s]\n",
      " 39%|███▉      | 5.54M/14.2M [00:16<00:27, 334kB/s]\n",
      " 39%|███▉      | 5.58M/14.2M [00:16<00:26, 336kB/s]\n",
      " 40%|███▉      | 5.62M/14.2M [00:16<00:25, 349kB/s]\n",
      " 40%|███▉      | 5.66M/14.2M [00:16<00:26, 342kB/s]\n",
      " 40%|████      | 5.70M/14.2M [00:16<00:25, 347kB/s]\n",
      " 41%|████      | 5.73M/14.2M [00:16<00:25, 345kB/s]\n",
      " 41%|████      | 5.77M/14.2M [00:16<00:25, 344kB/s]\n",
      " 41%|████      | 5.81M/14.2M [00:17<00:24, 351kB/s]\n",
      " 41%|████▏     | 5.85M/14.2M [00:17<00:24, 352kB/s]\n",
      " 42%|████▏     | 5.89M/14.2M [00:17<00:24, 358kB/s]\n",
      " 42%|████▏     | 5.93M/14.2M [00:17<00:23, 366kB/s]\n",
      " 42%|████▏     | 5.97M/14.2M [00:17<00:23, 366kB/s]\n",
      " 42%|████▏     | 6.01M/14.2M [00:17<00:23, 362kB/s]\n",
      " 43%|████▎     | 6.05M/14.2M [00:17<00:23, 363kB/s]\n",
      " 43%|████▎     | 6.09M/14.2M [00:17<00:23, 357kB/s]\n",
      " 43%|████▎     | 6.12M/14.2M [00:17<00:22, 367kB/s]\n",
      " 44%|████▎     | 6.16M/14.2M [00:18<00:23, 360kB/s]\n",
      " 44%|████▍     | 6.20M/14.2M [00:18<00:23, 361kB/s]\n",
      " 44%|████▍     | 6.24M/14.2M [00:18<00:22, 372kB/s]\n",
      " 44%|████▍     | 6.28M/14.2M [00:18<00:21, 377kB/s]\n",
      " 45%|████▍     | 6.32M/14.2M [00:18<00:22, 369kB/s]\n",
      " 45%|████▍     | 6.36M/14.2M [00:18<00:21, 374kB/s]\n",
      " 45%|████▌     | 6.40M/14.2M [00:18<00:22, 357kB/s]\n",
      " 45%|████▌     | 6.44M/14.2M [00:18<00:22, 367kB/s]\n",
      " 46%|████▌     | 6.48M/14.2M [00:18<00:21, 373kB/s]\n",
      " 46%|████▌     | 6.52M/14.2M [00:19<00:21, 376kB/s]\n",
      " 46%|████▋     | 6.55M/14.2M [00:19<00:21, 369kB/s]\n",
      " 47%|████▋     | 6.59M/14.2M [00:19<00:21, 375kB/s]\n",
      " 47%|████▋     | 6.63M/14.2M [00:19<00:21, 365kB/s]\n",
      " 47%|████▋     | 6.67M/14.2M [00:19<00:21, 361kB/s]\n",
      " 47%|████▋     | 6.71M/14.2M [00:19<00:21, 371kB/s]\n",
      " 48%|████▊     | 6.75M/14.2M [00:19<00:21, 364kB/s]\n",
      " 48%|████▊     | 6.79M/14.2M [00:19<00:20, 368kB/s]\n",
      " 48%|████▊     | 6.83M/14.2M [00:19<00:21, 359kB/s]\n",
      " 49%|████▊     | 6.87M/14.2M [00:20<00:20, 365kB/s]\n",
      " 49%|████▉     | 6.91M/14.2M [00:20<00:21, 350kB/s]\n",
      " 49%|████▉     | 6.95M/14.2M [00:20<00:21, 354kB/s]\n",
      " 49%|████▉     | 6.98M/14.2M [00:20<00:20, 364kB/s]\n",
      " 50%|████▉     | 7.02M/14.2M [00:20<00:21, 352kB/s]\n",
      " 50%|████▉     | 7.06M/14.2M [00:20<00:20, 357kB/s]\n",
      " 50%|█████     | 7.10M/14.2M [00:20<00:20, 359kB/s]\n",
      " 50%|█████     | 7.14M/14.2M [00:20<00:20, 358kB/s]\n",
      " 51%|█████     | 7.18M/14.2M [00:20<00:20, 358kB/s]\n",
      " 51%|█████     | 7.22M/14.2M [00:21<00:21, 339kB/s]\n",
      " 51%|█████▏    | 7.26M/14.2M [00:21<00:21, 343kB/s]\n",
      " 52%|█████▏    | 7.30M/14.2M [00:21<00:20, 346kB/s]\n",
      " 52%|█████▏    | 7.34M/14.2M [00:21<00:20, 356kB/s]\n",
      " 52%|█████▏    | 7.38M/14.2M [00:21<00:20, 355kB/s]\n",
      " 52%|█████▏    | 7.41M/14.2M [00:21<00:19, 359kB/s]\n",
      " 53%|█████▎    | 7.45M/14.2M [00:21<00:19, 367kB/s]\n",
      " 53%|█████▎    | 7.49M/14.2M [00:21<00:18, 368kB/s]\n",
      " 53%|█████▎    | 7.53M/14.2M [00:22<00:19, 359kB/s]\n",
      " 53%|█████▎    | 7.57M/14.2M [00:22<00:18, 365kB/s]\n",
      " 54%|█████▎    | 7.61M/14.2M [00:22<00:44, 154kB/s]\n",
      " 55%|█████▌    | 7.83M/14.2M [00:22<00:15, 442kB/s]\n",
      " 56%|█████▌    | 7.91M/14.2M [00:23<00:15, 418kB/s]\n",
      " 56%|█████▋    | 7.98M/14.2M [00:23<00:16, 405kB/s]\n",
      " 57%|█████▋    | 8.04M/14.2M [00:23<00:16, 395kB/s]\n",
      " 57%|█████▋    | 8.09M/14.2M [00:23<00:16, 389kB/s]\n",
      " 57%|█████▋    | 8.14M/14.2M [00:23<00:16, 378kB/s]\n",
      " 58%|█████▊    | 8.19M/14.2M [00:23<00:16, 385kB/s]\n",
      " 58%|█████▊    | 8.23M/14.2M [00:24<00:16, 373kB/s]\n",
      " 58%|█████▊    | 8.27M/14.2M [00:24<00:16, 381kB/s]\n",
      " 59%|█████▊    | 8.31M/14.2M [00:24<00:16, 374kB/s]\n",
      " 59%|█████▉    | 8.35M/14.2M [00:24<00:16, 372kB/s]\n",
      " 59%|█████▉    | 8.39M/14.2M [00:24<00:16, 369kB/s]\n",
      " 60%|█████▉    | 8.43M/14.2M [00:24<00:16, 375kB/s]\n",
      " 60%|█████▉    | 8.47M/14.2M [00:24<00:16, 368kB/s]\n",
      " 60%|██████    | 8.51M/14.2M [00:25<00:36, 162kB/s]\n",
      " 62%|██████▏   | 8.71M/14.2M [00:25<00:13, 430kB/s]\n",
      " 62%|██████▏   | 8.79M/14.2M [00:25<00:13, 409kB/s]\n",
      " 63%|██████▎   | 8.85M/14.2M [00:25<00:14, 395kB/s]\n",
      " 63%|██████▎   | 8.91M/14.2M [00:25<00:14, 391kB/s]\n",
      " 63%|██████▎   | 8.96M/14.2M [00:26<00:14, 386kB/s]\n",
      " 64%|██████▎   | 9.01M/14.2M [00:26<00:14, 380kB/s]\n",
      " 64%|██████▍   | 9.05M/14.2M [00:26<00:13, 383kB/s]\n",
      " 64%|██████▍   | 9.10M/14.2M [00:26<00:14, 377kB/s]\n",
      " 65%|██████▍   | 9.14M/14.2M [00:26<00:14, 367kB/s]\n",
      " 65%|██████▍   | 9.18M/14.2M [00:26<00:13, 375kB/s]\n",
      " 65%|██████▌   | 9.22M/14.2M [00:26<00:14, 361kB/s]\n",
      " 65%|██████▌   | 9.26M/14.2M [00:26<00:13, 372kB/s]\n",
      " 66%|██████▌   | 9.30M/14.2M [00:27<00:13, 367kB/s]\n",
      " 66%|██████▌   | 9.34M/14.2M [00:27<00:13, 372kB/s]\n",
      " 66%|██████▌   | 9.38M/14.2M [00:27<00:13, 372kB/s]\n",
      " 66%|██████▋   | 9.41M/14.2M [00:27<00:13, 366kB/s]\n",
      " 67%|██████▋   | 9.45M/14.2M [00:27<00:13, 365kB/s]\n",
      " 67%|██████▋   | 9.49M/14.2M [00:27<00:13, 374kB/s]\n",
      " 67%|██████▋   | 9.53M/14.2M [00:27<00:13, 368kB/s]\n",
      " 68%|██████▊   | 9.57M/14.2M [00:27<00:13, 357kB/s]\n",
      " 68%|██████▊   | 9.62M/14.2M [00:27<00:12, 370kB/s]\n",
      " 68%|██████▊   | 9.66M/14.2M [00:28<00:12, 374kB/s]\n",
      " 68%|██████▊   | 9.70M/14.2M [00:28<00:12, 370kB/s]\n",
      " 69%|██████▉   | 9.73M/14.2M [00:28<00:12, 363kB/s]\n",
      " 69%|██████▉   | 9.77M/14.2M [00:28<00:12, 373kB/s]\n",
      " 69%|██████▉   | 9.81M/14.2M [00:28<00:12, 367kB/s]\n",
      " 70%|██████▉   | 9.85M/14.2M [00:28<00:12, 369kB/s]\n",
      " 70%|██████▉   | 9.89M/14.2M [00:28<00:12, 359kB/s]\n",
      " 70%|███████   | 9.93M/14.2M [00:28<00:12, 363kB/s]\n",
      " 70%|███████   | 9.97M/14.2M [00:28<00:11, 367kB/s]\n",
      " 71%|███████   | 10.0M/14.2M [00:29<00:11, 364kB/s]\n",
      " 71%|███████   | 10.0M/14.2M [00:29<00:11, 361kB/s]\n",
      " 71%|███████   | 10.1M/14.2M [00:29<00:11, 362kB/s]\n",
      " 72%|███████▏  | 10.1M/14.2M [00:29<00:11, 362kB/s]\n",
      " 72%|███████▏  | 10.2M/14.2M [00:29<00:11, 354kB/s]\n",
      " 72%|███████▏  | 10.2M/14.2M [00:29<00:11, 361kB/s]\n",
      " 72%|███████▏  | 10.2M/14.2M [00:29<00:11, 364kB/s]\n",
      " 73%|███████▎  | 10.3M/14.2M [00:29<00:10, 370kB/s]\n",
      " 73%|███████▎  | 10.3M/14.2M [00:30<00:10, 370kB/s]\n",
      " 73%|███████▎  | 10.4M/14.2M [00:30<00:10, 372kB/s]\n",
      " 73%|███████▎  | 10.4M/14.2M [00:30<00:10, 366kB/s]\n",
      " 74%|███████▎  | 10.4M/14.2M [00:30<00:10, 355kB/s]\n",
      " 74%|███████▍  | 10.5M/14.2M [00:30<00:10, 370kB/s]\n",
      " 74%|███████▍  | 10.5M/14.2M [00:30<00:10, 370kB/s]\n",
      " 75%|███████▍  | 10.6M/14.2M [00:30<00:10, 370kB/s]\n",
      " 75%|███████▍  | 10.6M/14.2M [00:30<00:10, 370kB/s]\n",
      " 75%|███████▌  | 10.6M/14.2M [00:30<00:10, 365kB/s]\n",
      " 75%|███████▌  | 10.7M/14.2M [00:31<00:10, 363kB/s]\n",
      " 76%|███████▌  | 10.7M/14.2M [00:31<00:09, 373kB/s]\n",
      " 76%|███████▌  | 10.8M/14.2M [00:31<00:09, 369kB/s]\n",
      " 76%|███████▌  | 10.8M/14.2M [00:31<00:09, 373kB/s]\n",
      " 76%|███████▋  | 10.8M/14.2M [00:31<00:10, 343kB/s]\n",
      " 77%|███████▋  | 10.9M/14.2M [00:31<00:09, 368kB/s]\n",
      " 77%|███████▋  | 10.9M/14.2M [00:31<00:09, 368kB/s]\n",
      " 77%|███████▋  | 11.0M/14.2M [00:31<00:09, 366kB/s]\n",
      " 78%|███████▊  | 11.0M/14.2M [00:31<00:09, 362kB/s]\n",
      " 78%|███████▊  | 11.0M/14.2M [00:32<00:09, 361kB/s]\n",
      " 78%|███████▊  | 11.1M/14.2M [00:32<00:08, 369kB/s]\n",
      " 78%|███████▊  | 11.1M/14.2M [00:32<00:08, 365kB/s]\n",
      " 79%|███████▊  | 11.1M/14.2M [00:32<00:08, 368kB/s]\n",
      " 79%|███████▉  | 11.2M/14.2M [00:32<00:08, 367kB/s]\n",
      " 79%|███████▉  | 11.2M/14.2M [00:32<00:08, 368kB/s]\n",
      " 80%|███████▉  | 11.3M/14.2M [00:32<00:08, 377kB/s]\n",
      " 80%|███████▉  | 11.3M/14.2M [00:32<00:08, 365kB/s]\n",
      " 80%|████████  | 11.3M/14.2M [00:32<00:07, 372kB/s]\n",
      " 80%|████████  | 11.4M/14.2M [00:33<00:07, 371kB/s]\n",
      " 81%|████████  | 11.4M/14.2M [00:33<00:08, 349kB/s]\n",
      " 81%|████████  | 11.5M/14.2M [00:33<00:07, 368kB/s]\n",
      " 81%|████████▏ | 11.5M/14.2M [00:33<00:07, 374kB/s]\n",
      " 82%|████████▏ | 11.5M/14.2M [00:33<00:07, 369kB/s]\n",
      " 82%|████████▏ | 11.6M/14.2M [00:33<00:07, 370kB/s]\n",
      " 82%|████████▏ | 11.6M/14.2M [00:33<00:07, 364kB/s]\n",
      " 82%|████████▏ | 11.7M/14.2M [00:33<00:07, 372kB/s]\n",
      " 83%|████████▎ | 11.7M/14.2M [00:33<00:07, 358kB/s]\n",
      " 83%|████████▎ | 11.8M/14.2M [00:34<00:06, 373kB/s]\n",
      " 83%|████████▎ | 11.8M/14.2M [00:34<00:06, 373kB/s]\n",
      " 84%|████████▎ | 11.8M/14.2M [00:34<00:06, 378kB/s]\n",
      " 84%|████████▍ | 11.9M/14.2M [00:34<00:06, 372kB/s]\n",
      " 84%|████████▍ | 11.9M/14.2M [00:34<00:06, 380kB/s]\n",
      " 84%|████████▍ | 11.9M/14.2M [00:35<00:15, 153kB/s]\n",
      " 86%|████████▌ | 12.2M/14.2M [00:35<00:04, 438kB/s]\n",
      " 87%|████████▋ | 12.2M/14.2M [00:35<00:04, 416kB/s]\n",
      " 87%|████████▋ | 12.3M/14.2M [00:35<00:04, 414kB/s]\n",
      " 87%|████████▋ | 12.4M/14.2M [00:35<00:04, 393kB/s]\n",
      " 88%|████████▊ | 12.4M/14.2M [00:36<00:04, 395kB/s]\n",
      " 88%|████████▊ | 12.5M/14.2M [00:36<00:04, 387kB/s]\n",
      " 88%|████████▊ | 12.5M/14.2M [00:36<00:04, 386kB/s]\n",
      " 89%|████████▊ | 12.6M/14.2M [00:36<00:04, 375kB/s]\n",
      " 89%|████████▉ | 12.6M/14.2M [00:36<00:04, 367kB/s]\n",
      " 89%|████████▉ | 12.6M/14.2M [00:36<00:04, 373kB/s]\n",
      " 90%|████████▉ | 12.7M/14.2M [00:36<00:04, 368kB/s]\n",
      " 90%|████████▉ | 12.7M/14.2M [00:36<00:04, 351kB/s]\n",
      " 90%|█████████ | 12.8M/14.2M [00:36<00:04, 356kB/s]\n",
      " 90%|█████████ | 12.8M/14.2M [00:37<00:04, 352kB/s]\n",
      " 91%|█████████ | 12.8M/14.2M [00:37<00:03, 356kB/s]\n",
      " 91%|█████████ | 12.9M/14.2M [00:37<00:08, 164kB/s]\n",
      " 92%|█████████▏| 13.1M/14.2M [00:37<00:02, 421kB/s]\n",
      " 93%|█████████▎| 13.1M/14.2M [00:38<00:02, 391kB/s]\n",
      " 93%|█████████▎| 13.2M/14.2M [00:38<00:04, 242kB/s]\n",
      " 94%|█████████▍| 13.3M/14.2M [00:38<00:02, 339kB/s]\n",
      " 95%|█████████▍| 13.4M/14.2M [00:39<00:02, 332kB/s]\n",
      " 95%|█████████▍| 13.4M/14.2M [00:39<00:02, 302kB/s]\n",
      " 95%|█████████▌| 13.5M/14.2M [00:39<00:02, 303kB/s]\n",
      " 96%|█████████▌| 13.5M/14.2M [00:39<00:02, 307kB/s]\n",
      " 96%|█████████▌| 13.6M/14.2M [00:39<00:02, 296kB/s]\n",
      " 96%|█████████▌| 13.6M/14.2M [00:39<00:01, 295kB/s]\n",
      " 96%|█████████▋| 13.6M/14.2M [00:40<00:01, 284kB/s]\n",
      " 97%|█████████▋| 13.7M/14.2M [00:40<00:01, 282kB/s]\n",
      " 97%|█████████▋| 13.7M/14.2M [00:40<00:01, 276kB/s]\n",
      " 97%|█████████▋| 13.7M/14.2M [00:40<00:01, 266kB/s]\n",
      " 97%|█████████▋| 13.8M/14.2M [00:40<00:01, 273kB/s]\n",
      " 97%|█████████▋| 13.8M/14.2M [00:40<00:01, 278kB/s]\n",
      " 98%|█████████▊| 13.8M/14.2M [00:40<00:01, 287kB/s]\n",
      " 98%|█████████▊| 13.9M/14.2M [00:40<00:01, 299kB/s]\n",
      " 98%|█████████▊| 13.9M/14.2M [00:40<00:00, 318kB/s]\n",
      " 98%|█████████▊| 13.9M/14.2M [00:41<00:00, 320kB/s]\n",
      " 99%|█████████▊| 14.0M/14.2M [00:41<00:00, 316kB/s]\n",
      " 99%|█████████▉| 14.0M/14.2M [00:41<00:00, 328kB/s]\n",
      " 99%|█████████▉| 14.0M/14.2M [00:41<00:00, 335kB/s]\n",
      " 99%|█████████▉| 14.1M/14.2M [00:41<00:00, 342kB/s]\n",
      "100%|█████████▉| 14.1M/14.2M [00:41<00:00, 346kB/s]\n",
      "100%|█████████▉| 14.2M/14.2M [00:41<00:00, 336kB/s]\n",
      "100%|██████████| 14.2M/14.2M [00:43<00:00, 342kB/s]\n"
     ]
    }
   ],
   "source": [
    "#!kaggle competitions submit tabular-playground-series-nov-2021 -f submission.csv -m ''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "102988cd41447315534c958c58e308e7e3484eb005f63e4d7c4500d870bbba42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('kaggle': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
