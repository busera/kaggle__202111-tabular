{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-11-05:\n",
    "- Initial version. New competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open tasks\n",
    "- TODO: Add LogisticRegression classifier\n",
    "- TODO: Add better function to submit best baseline results (stacked or non-stacked)\n",
    "- TODO: Write function to write scores into a dataframe/csv-file for better documentation and tracking: Switch to MLflow\n",
    "- TODO: Refactor write_scores_to_json() or replace it with df/csv-file approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the **stage two** notebook is to calculate the **baseline score of un-optimized ML algorithms** as a baseline for future optimization, including feature selection/reduction, feature normalization/transformation, and hyper-parameters tuning. The workflow will use the optimized dataframes (reduced storage and memory usage). For this competition, we are focusing on the **ROC AUC score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Basic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for cpu count\n",
    "import configparser # to load standard config.ini\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib, requests # for Telegram notifications\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf # to check GPU support\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs used: 8\n"
     ]
    }
   ],
   "source": [
    "# Load external config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../src/config.ini\")\n",
    "\n",
    "PATH_DATA_RAW = config[\"PATHS\"][\"PATH_DATA_RAW\"]\n",
    "PATH_DATA_INT = config[\"PATHS\"][\"PATH_DATA_INT\"]\n",
    "PATH_DATA_PRO = config[\"PATHS\"][\"PATH_DATA_PRO\"]\n",
    "PATH_REPORTS = config[\"PATHS\"][\"PATH_REPORTS\"]\n",
    "PATH_MODELS = config[\"PATHS\"][\"PATH_MODELS\"]\n",
    "PATH_SUB = config[\"PATHS\"][\"PATH_SUB\"]\n",
    "\n",
    "# Telegram Bot\n",
    "token = config[\"TELEGRAM\"][\"token\"]\n",
    "chat_id = config[\"TELEGRAM\"][\"chat_id\"]\n",
    "FILENAME_NB = \"02_baseline_models\" # for Telegram messages\n",
    "\n",
    "# Set global randome state\n",
    "rnd_state = 42\n",
    "\n",
    "# Define available cpu cores\n",
    "n_cpu = os.cpu_count()\n",
    "print(\"Number of CPUs used:\", n_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "WARNING:tensorflow:From C:\\Users\\buser\\AppData\\Local\\Temp/ipykernel_20644/966524355.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checking GPU support\n",
    "print(tf.test.is_built_with_cuda())  # True\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))  # True\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_telegram_message(message):\n",
    "    \"\"\"Sending messages to Telegram bot via requests.get().\"\"\"\n",
    "    \n",
    "    message = f\"{FILENAME_NB}:\\n{message}\"\n",
    "\n",
    "    # Using \"try and except\" to ensure that the notebook execution will not be stopped only because of problems with the bot.\n",
    "    # Example: No network connection.\n",
    "    # ISSUE: Be careful, an error messages will leak your Telegram Bot Token when uploaded to GitHub.\n",
    "    try:\n",
    "        url = 'https://api.telegram.org/bot%s/sendMessage?chat_id=%s&text=%s'%(token, chat_id, urllib.parse.quote_plus(message))\n",
    "        _ = requests.get(url, timeout=10)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('\\n\\nSending message to Telegram Bot was not successful.\\n\\n')\n",
    "        print(e)\n",
    "        \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_train_scores(model, X_train, y_train, y_train_pred):\n",
    "    # Training set performance\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)  # Calculate Accuracy\n",
    "    train_mcc = matthews_corrcoef(y_train, y_train_pred)  # Calculate MCC\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")  # Calculate F1-score\n",
    "    train_rocauc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "    \n",
    "    return train_accuracy, train_mcc, train_f1, train_rocauc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_scores(model, X_valid, y_valid, y_valid_pred):\n",
    "    # Validation set performance\n",
    "    valid_accuracy = accuracy_score(y_valid, y_valid_pred)  # Calculate Accuracy\n",
    "    valid_mcc = matthews_corrcoef(y_valid, y_valid_pred)  # Calculate MCC\n",
    "    valid_f1 = f1_score(y_valid, y_valid_pred, average=\"weighted\")  # Calculate F1-score\n",
    "    valid_rocauc = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "    return valid_accuracy, valid_mcc, valid_f1, valid_rocauc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    print(\"Model performance for Training set\")\n",
    "    print(\"- Accuracy: %s\" % train_accuracy)\n",
    "    print(\"- MCC: %s\" % train_mcc)\n",
    "    print(\"- F1 score: %s\" % train_f1)\n",
    "    print(\"- ROC AUC score: %s\" % train_rocauc)\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Model performance for Validation set\")\n",
    "    print(\"- Accuracy: %s\" % valid_accuracy)\n",
    "    print(\"- MCC: %s\" % valid_mcc)\n",
    "    print(\"- F1 score: %s\" % valid_f1)\n",
    "    print(\"- ROC AUC score: %s\" % valid_rocauc)\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scores_to_json(filename):\n",
    "    dummy_scores_dict = {}\n",
    "    dummy_scores_list = []\n",
    "\n",
    "    dummy_scores_dict['Accuracy Train'] = train_accuracy\n",
    "    dummy_scores_dict['MCC Train'] = train_mcc\n",
    "    dummy_scores_dict['F1 Train'] = train_f1\n",
    "    dummy_scores_dict['ROC AUC Train'] = train_rocauc\n",
    "    dummy_scores_list.append(dummy_scores_dict)\n",
    "\n",
    "    dummy_scores_dict = {}\n",
    "    dummy_scores_dict['Accuracy Valid'] = valid_accuracy\n",
    "    dummy_scores_dict['MCC Valid'] = valid_mcc\n",
    "    dummy_scores_dict['F1 Valid'] = valid_f1\n",
    "    dummy_scores_dict['ROC AUC Valid'] = valid_rocauc\n",
    "    dummy_scores_list.append(dummy_scores_dict)\n",
    "\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Serializing and write json file\n",
    "    json_object = json.dumps(dummy_scores_list, indent = 4) \n",
    "    filename =  now+'_'+filename\n",
    "    with open(PATH_REPORTS + filename, \"w\") as outfile: \n",
    "        outfile.write(json_object)\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(PATH_DATA_INT + \"train-opt.pkl\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 102)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing sample size\n",
    "# sample_size = 500000\n",
    "# X = train_df[:sample_size]\n",
    "# y = train_df[:sample_size]['target']\n",
    "# assert y.index.tolist() == X.index.tolist()\n",
    "# X = X.drop(['id','target'], axis=1)\n",
    "\n",
    "# Using full dataset\n",
    "#X = train_df.drop([\"id\", \"target\"], axis=1).to_numpy()\n",
    "#y = train_df[\"target\"].to_numpy()\n",
    "\n",
    "\n",
    "# Using numpy arrays: https://vitalflux.com/pandas-dataframe-vs-numpy-array-what-to-use/\n",
    "X = train_df.drop([\"id\", \"target\"], axis=1).values # using numpy array\n",
    "y = train_df[\"target\"].values # using numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 100), (600000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Baseline Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable / disable baseline classifiers\n",
    "# Do not forget to add/remove classifiers in the stacking section, accordingly\n",
    "dummy_enabled = \"yes\"\n",
    "xgbc_enabled = \"yes\"\n",
    "lgbc_enabled = \"yes\"\n",
    "ctbc_enabled = \"yes\"\n",
    "rfc_enabled = \"no\" # Carefurl: tree grows big: .pkl file is around 1GB\n",
    "dtc_enabled = \"yes\"\n",
    "knnc_enabled = \"no\" # disable when sample size > 100.000\n",
    "mlpc_enabled = \"yes\"\n",
    "\n",
    "# Evaluation Metric\n",
    "eval_metric = \"AUC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=rnd_state, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((402000, 100), (198000, 100))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending for first bot message\n",
    "message = \"------------START------------\"\n",
    "send_telegram_message(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.49971641791044774\n",
      "- MCC: -0.0007158149923818674\n",
      "- F1 score: 0.4997153862573974\n",
      "- ROC AUC score: 0.4992864590238203\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.5010555555555556\n",
      "- MCC: 0.001968000804853239\n",
      "- F1 score: 0.5010558271733098\n",
      "- ROC AUC score: 0.4976358338031067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Define model\n",
    "duc = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "if dummy_enabled == \"yes\":\n",
    "    try:\n",
    "        # Train model\n",
    "        duc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = duc.predict(X_train)\n",
    "        y_valid_pred = duc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "            duc, X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "            duc, X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        print_scores()\n",
    "        filename = \"dummy_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        #message = f\"DummyClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        #send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {duc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f\"\\n{e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.739636815920398\n",
      "- MCC: 0.47915750722924866\n",
      "- F1 score: 0.7396045989898449\n",
      "- ROC AUC score: 0.7908411173210788\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.6898131313131313\n",
      "- MCC: 0.3794717164213431\n",
      "- F1 score: 0.6897757777983862\n",
      "- ROC AUC score: 0.7302524575048538\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "if xgbc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        xgbc = xgb.XGBClassifier(\n",
    "            random_state=rnd_state,\n",
    "            n_jobs=n_cpu,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=eval_metric.lower(),\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        xgbc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = xgbc.predict(X_train)\n",
    "        y_valid_pred = xgbc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "            xgbc, X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "            xgbc, X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"xgbc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"xgbc_baseline_model.pkl\"\n",
    "        joblib.dump(xgbc, PATH_MODELS + filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"XGBClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {xgbc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f\"\\n{e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.711634328358209\n",
      "- MCC: 0.42313528003810374\n",
      "- F1 score: 0.7115611478353585\n",
      "- ROC AUC score: 0.7523186556056192\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.6935707070707071\n",
      "- MCC: 0.3869851339188961\n",
      "- F1 score: 0.6934901492194795\n",
      "- ROC AUC score: 0.7324083009279608\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "if lgbc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        lgbc = lgb.LGBMClassifier(\n",
    "            random_state=rnd_state,\n",
    "            n_jobs=n_cpu,\n",
    "            eval_metric=eval_metric\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        lgbc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = lgbc.predict(X_train)\n",
    "        y_valid_pred = lgbc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(lgbc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(lgbc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"lgbc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"lgbc_baseline_model.pkl\"\n",
    "        joblib.dump(lgbc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"LGBClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {lgbc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.721455223880597\n",
      "- MCC: 0.4427828186768833\n",
      "- F1 score: 0.7213978211816185\n",
      "- ROC AUC score: 0.751828573388908\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.712570707070707\n",
      "- MCC: 0.4250031524427747\n",
      "- F1 score: 0.7125145062780892\n",
      "- ROC AUC score: 0.7431837490569371\n"
     ]
    }
   ],
   "source": [
    "import catboost as ctb\n",
    "\n",
    "if ctbc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        ctbc = ctb.CatBoostClassifier(\n",
    "            random_state=rnd_state,\n",
    "            verbose=0,\n",
    "            eval_metric=eval_metric,\n",
    "            task_type=\"GPU\"\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        ctbc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = ctbc.predict(X_train)\n",
    "        y_valid_pred = ctbc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(ctbc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(ctbc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"ctbc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"ctbc_baseline_model.pkl\"\n",
    "        joblib.dump(ctbc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = (f\"CatBoostClassifier finished. Validation AUC ROC Score: {valid_rocauc}\")\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {ctbc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if rfc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        rfc = RandomForestClassifier(random_state=rnd_state, n_jobs=n_cpu)\n",
    "\n",
    "        # Train model\n",
    "        rfc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = rfc.predict(X_train)\n",
    "        y_valid_pred = rfc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(rfc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(rfc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"rfc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"rfc_baseline_model.pkl\"\n",
    "        joblib.dump(rfc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"RandomForestClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {rfc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.5946915422885573\n",
      "- MCC: 0.18987298499929253\n",
      "- F1 score: 0.5921751169391201\n",
      "- ROC AUC score: 0.6269208288033784\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.5906565656565657\n",
      "- MCC: 0.18170968165367538\n",
      "- F1 score: 0.5880974878412564\n",
      "- ROC AUC score: 0.6216633988408427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "if dtc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        dtc = DecisionTreeClassifier(max_depth=5, random_state=rnd_state)\n",
    "\n",
    "        # Train model\n",
    "        dtc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = dtc.predict(X_train)\n",
    "        y_valid_pred = dtc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(dtc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(dtc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"dtc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"dtc_baseline_model.pkl\"\n",
    "        joblib.dump(dtc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"DecisionTreeClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {dtc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "if knnc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        knnc = KNeighborsClassifier(n_neighbors=3, n_jobs=n_cpu)\n",
    "\n",
    "        # Train model\n",
    "        knnc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = knnc.predict(X_train)\n",
    "        y_valid_pred = knnc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(knnc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(knnc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"knnc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"knnc_baseline_model.pkl\"\n",
    "        joblib.dump(knnc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"KNNClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {knnc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.6940273631840796\n",
      "- MCC: 0.39256028607451837\n",
      "- F1 score: 0.6928719489792595\n",
      "- ROC AUC score: 0.7337734122917466\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.6954191919191919\n",
      "- MCC: 0.39549752057732285\n",
      "- F1 score: 0.6942285070921432\n",
      "- ROC AUC score: 0.7359253109205993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if mlpc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        mlpc = MLPClassifier(alpha=1, max_iter=200, random_state=rnd_state)\n",
    "\n",
    "        # Train model\n",
    "        mlpc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = mlpc.predict(X_train)\n",
    "        y_valid_pred = mlpc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(mlpc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(mlpc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"mlpc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"mlpc_baseline_model.pkl\"\n",
    "        joblib.dump(mlpc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"MLPClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {mlpc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingClassifier (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/stacking-made-easy-with-sklearn-e27a0793c92b\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier # only works with estimators from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    # (\"rfc\", rfc),\n",
    "    (\"dtc\", dtc),\n",
    "    # (\"knnc\", knnc),\n",
    "    (\"mlpc\", mlpc),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=rnd_state)\n",
    "\n",
    "# Build stack model\n",
    "stack_skl_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator) \n",
    "\n",
    "try:\n",
    "    # Train stacked model\n",
    "    stack_skl_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = stack_skl_model.predict(X_train)\n",
    "    y_valid_pred = stack_skl_model.predict(X_valid)\n",
    "\n",
    "    # Training set performance\n",
    "    train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "        stack_skl_model, X_train, y_train, y_train_pred\n",
    "    )\n",
    "\n",
    "    # Validation set performance\n",
    "    valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "        stack_skl_model, X_valid, y_valid, y_valid_pred\n",
    "    )\n",
    "\n",
    "    # Print and write scores\n",
    "    print_scores()\n",
    "    filename = \"stack_sklearn_baseline_scores.json\"\n",
    "    write_scores_to_json(filename)\n",
    "\n",
    "    # Store base model\n",
    "    filename = \"stack_sklearn_baseline_model.pkl\"\n",
    "    joblib.dump(stack_skl_model, PATH_MODELS+filename)\n",
    "\n",
    "    # Send messages\n",
    "    message = f\"Stacking (sklearn) finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "    send_telegram_message(message)\n",
    "\n",
    "except Exception as e:\n",
    "        message = f\"\\nFitting of {stack_skl_model} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingCVClassifier (mlxtend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://developer.ibm.com/articles/stack-machine-learning-models-get-better-results/\n",
    "- http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: xgbclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:   48.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: lgbmclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: catboostclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:  4.3min finished\n",
      "C:\\Users\\buser\\miniconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buser\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.770744776119403\n",
      "- MCC: 0.5432228202079334\n",
      "- F1 score: 0.7703951329077331\n",
      "- ROC AUC score: 0.8451570677452912\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.765439393939394\n",
      "- MCC: 0.5319586543941238\n",
      "- F1 score: 0.765214664396255\n",
      "- ROC AUC score: 0.8414691798204225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "lr = LogisticRegression(random_state=rnd_state)\n",
    "\n",
    "stack_mlx_model = StackingCVClassifier(\n",
    "    classifiers=[xgbc, lgbc, ctbc],\n",
    "    meta_classifier=lr,\n",
    "    cv=5,\n",
    "    use_features_in_secondary=True,\n",
    "    store_train_meta_features=True,\n",
    "    shuffle=True,\n",
    "    random_state=rnd_state,\n",
    "    verbose=1,\n",
    "    n_jobs=n_cpu\n",
    ")\n",
    "\n",
    "try:\n",
    "    stack_mlx_model.fit(X_train, y_train)\n",
    "    y_valid_pred = stack_mlx_model.predict(X_valid)\n",
    "\n",
    "    # Training set performance\n",
    "    train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "        stack_mlx_model, X_train, y_train, y_train_pred\n",
    "    )\n",
    "\n",
    "    # Validation set performance\n",
    "    valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "        stack_mlx_model, X_valid, y_valid, y_valid_pred\n",
    "    )\n",
    "\n",
    "    # Print and write scores\n",
    "    print_scores()\n",
    "    filename = \"stack_sklearn_baseline_scores.json\"\n",
    "    write_scores_to_json(filename)\n",
    "\n",
    "    # Store base model\n",
    "    filename = \"stack_mlxtend_baseline_model.pkl\"\n",
    "    joblib.dump(stack_mlx_model, PATH_MODELS+filename)\n",
    "\n",
    "    # Send messages\n",
    "    message = f\"Stacking (mlxtend) finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "    send_telegram_message(message)\n",
    "\n",
    "except Exception as e:\n",
    "        message = f\"\\nFitting of {stack_mlx_model} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 285)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(PATH_DATA_INT + \"test-opt.pkl\")\n",
    "X_test = test_df.drop(\"id\", axis=1).values\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (best) model on \"full\" data set\n",
    "# _ = stack_skl_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_pred = stack_skl_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit (Best) Baseline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section needs to be finalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05_submission_stack_mlx_model-baseline.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "objective = \"stack_mlx_model-baseline\"\n",
    "\n",
    "curr_submission_fn = f\"{now}_submission_{objective}.csv\"\n",
    "\n",
    "my_submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": y_test_pred})\n",
    "my_submission.to_csv(PATH_SUB + curr_submission_fn, index=False)\n",
    "\n",
    "print(curr_submission_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Tabular Playground Series - Nov 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/5.25M [00:00<?, ?B/s]\n",
      "  0%|          | 8.00k/5.25M [00:00<01:44, 52.7kB/s]\n",
      "  2%|▏         | 96.0k/5.25M [00:00<00:11, 451kB/s] \n",
      "  4%|▎         | 200k/5.25M [00:00<00:07, 682kB/s] \n",
      "  5%|▌         | 280k/5.25M [00:00<00:10, 485kB/s]\n",
      "  6%|▋         | 344k/5.25M [00:00<00:11, 438kB/s]\n",
      "  7%|▋         | 400k/5.25M [00:00<00:11, 433kB/s]\n",
      "  8%|▊         | 448k/5.25M [00:01<00:12, 417kB/s]\n",
      "  9%|▉         | 496k/5.25M [00:01<00:13, 383kB/s]\n",
      " 10%|▉         | 536k/5.25M [00:01<00:12, 385kB/s]\n",
      " 11%|█         | 584k/5.25M [00:01<00:12, 404kB/s]\n",
      " 12%|█▏        | 632k/5.25M [00:01<00:12, 391kB/s]\n",
      " 13%|█▎        | 672k/5.25M [00:01<00:12, 387kB/s]\n",
      " 13%|█▎        | 712k/5.25M [00:01<00:12, 370kB/s]\n",
      " 14%|█▍        | 752k/5.25M [00:01<00:12, 372kB/s]\n",
      " 15%|█▍        | 792k/5.25M [00:02<00:12, 374kB/s]\n",
      " 15%|█▌        | 832k/5.25M [00:02<00:12, 373kB/s]\n",
      " 19%|█▊        | 0.98M/5.25M [00:02<00:06, 722kB/s]\n",
      " 20%|█▉        | 1.05M/5.25M [00:02<00:07, 557kB/s]\n",
      " 21%|██        | 1.11M/5.25M [00:02<00:08, 502kB/s]\n",
      " 22%|██▏       | 1.16M/5.25M [00:02<00:10, 425kB/s]\n",
      " 23%|██▎       | 1.21M/5.25M [00:02<00:09, 437kB/s]\n",
      " 24%|██▍       | 1.26M/5.25M [00:03<00:10, 400kB/s]\n",
      " 25%|██▍       | 1.30M/5.25M [00:03<00:09, 416kB/s]\n",
      " 26%|██▌       | 1.35M/5.25M [00:03<00:10, 401kB/s]\n",
      " 27%|██▋       | 1.40M/5.25M [00:03<00:10, 390kB/s]\n",
      " 27%|██▋       | 1.44M/5.25M [00:03<00:10, 390kB/s]\n",
      " 28%|██▊       | 1.48M/5.25M [00:04<00:23, 165kB/s]\n",
      " 32%|███▏      | 1.68M/5.25M [00:04<00:11, 339kB/s]\n",
      " 34%|███▍      | 1.80M/5.25M [00:04<00:07, 452kB/s]\n",
      " 35%|███▌      | 1.86M/5.25M [00:04<00:08, 420kB/s]\n",
      " 36%|███▋      | 1.91M/5.25M [00:05<00:16, 213kB/s]\n",
      " 40%|███▉      | 2.09M/5.25M [00:05<00:08, 378kB/s]\n",
      " 42%|████▏     | 2.18M/5.25M [00:05<00:08, 367kB/s]\n",
      " 43%|████▎     | 2.25M/5.25M [00:06<00:08, 356kB/s]\n",
      " 44%|████▍     | 2.31M/5.25M [00:06<00:08, 351kB/s]\n",
      " 45%|████▌     | 2.37M/5.25M [00:06<00:08, 356kB/s]\n",
      " 46%|████▌     | 2.41M/5.25M [00:06<00:08, 358kB/s]\n",
      " 47%|████▋     | 2.46M/5.25M [00:06<00:08, 357kB/s]\n",
      " 48%|████▊     | 2.51M/5.25M [00:06<00:08, 352kB/s]\n",
      " 49%|████▊     | 2.55M/5.25M [00:07<00:08, 335kB/s]\n",
      " 49%|████▉     | 2.59M/5.25M [00:07<00:08, 342kB/s]\n",
      " 50%|█████     | 2.63M/5.25M [00:07<00:09, 293kB/s]\n",
      " 51%|█████     | 2.66M/5.25M [00:07<00:18, 149kB/s]\n",
      " 53%|█████▎    | 2.80M/5.25M [00:08<00:08, 303kB/s]\n",
      " 54%|█████▍    | 2.85M/5.25M [00:08<00:07, 319kB/s]\n",
      " 55%|█████▌    | 2.91M/5.25M [00:08<00:07, 318kB/s]\n",
      " 56%|█████▋    | 2.95M/5.25M [00:08<00:08, 293kB/s]\n",
      " 57%|█████▋    | 2.99M/5.25M [00:08<00:08, 284kB/s]\n",
      " 58%|█████▊    | 3.03M/5.25M [00:08<00:07, 298kB/s]\n",
      " 59%|█████▊    | 3.07M/5.25M [00:09<00:07, 307kB/s]\n",
      " 59%|█████▉    | 3.11M/5.25M [00:09<00:06, 323kB/s]\n",
      " 60%|██████    | 3.15M/5.25M [00:09<00:06, 319kB/s]\n",
      " 61%|██████    | 3.19M/5.25M [00:09<00:07, 283kB/s]\n",
      " 62%|██████▏   | 3.25M/5.25M [00:09<00:06, 338kB/s]\n",
      " 63%|██████▎   | 3.30M/5.25M [00:09<00:05, 352kB/s]\n",
      " 64%|██████▎   | 3.34M/5.25M [00:09<00:06, 306kB/s]\n",
      " 65%|██████▍   | 3.39M/5.25M [00:10<00:07, 245kB/s]\n",
      " 66%|██████▋   | 3.48M/5.25M [00:10<00:05, 348kB/s]\n",
      " 67%|██████▋   | 3.52M/5.25M [00:10<00:05, 350kB/s]\n",
      " 68%|██████▊   | 3.56M/5.25M [00:10<00:04, 357kB/s]\n",
      " 69%|██████▊   | 3.60M/5.25M [00:10<00:06, 273kB/s]\n",
      " 70%|██████▉   | 3.66M/5.25M [00:10<00:04, 341kB/s]\n",
      " 71%|███████   | 3.70M/5.25M [00:11<00:04, 347kB/s]\n",
      " 71%|███████▏  | 3.74M/5.25M [00:11<00:04, 328kB/s]\n",
      " 72%|███████▏  | 3.78M/5.25M [00:11<00:04, 330kB/s]\n",
      " 73%|███████▎  | 3.82M/5.25M [00:11<00:04, 321kB/s]\n",
      " 74%|███████▎  | 3.86M/5.25M [00:11<00:04, 294kB/s]\n",
      " 75%|███████▍  | 3.91M/5.25M [00:11<00:04, 339kB/s]\n",
      " 75%|███████▌  | 3.95M/5.25M [00:11<00:03, 345kB/s]\n",
      " 76%|███████▌  | 3.99M/5.25M [00:12<00:03, 337kB/s]\n",
      " 77%|███████▋  | 4.03M/5.25M [00:12<00:03, 349kB/s]\n",
      " 78%|███████▊  | 4.07M/5.25M [00:12<00:03, 360kB/s]\n",
      " 78%|███████▊  | 4.11M/5.25M [00:12<00:03, 354kB/s]\n",
      " 79%|███████▉  | 4.15M/5.25M [00:12<00:03, 350kB/s]\n",
      " 80%|███████▉  | 4.19M/5.25M [00:12<00:03, 347kB/s]\n",
      " 81%|████████  | 4.23M/5.25M [00:12<00:05, 208kB/s]\n",
      " 83%|████████▎ | 4.35M/5.25M [00:13<00:02, 399kB/s]\n",
      " 84%|████████▍ | 4.41M/5.25M [00:13<00:02, 404kB/s]\n",
      " 85%|████████▌ | 4.46M/5.25M [00:13<00:02, 390kB/s]\n",
      " 86%|████████▌ | 4.51M/5.25M [00:13<00:02, 379kB/s]\n",
      " 87%|████████▋ | 4.55M/5.25M [00:13<00:01, 364kB/s]\n",
      " 88%|████████▊ | 4.60M/5.25M [00:13<00:01, 380kB/s]\n",
      " 89%|████████▊ | 4.65M/5.25M [00:13<00:01, 379kB/s]\n",
      " 89%|████████▉ | 4.69M/5.25M [00:14<00:01, 346kB/s]\n",
      " 90%|█████████ | 4.73M/5.25M [00:14<00:01, 361kB/s]\n",
      " 91%|█████████ | 4.77M/5.25M [00:14<00:01, 360kB/s]\n",
      " 92%|█████████▏| 4.81M/5.25M [00:14<00:01, 349kB/s]\n",
      " 92%|█████████▏| 4.85M/5.25M [00:14<00:01, 363kB/s]\n",
      " 93%|█████████▎| 4.89M/5.25M [00:14<00:01, 363kB/s]\n",
      " 94%|█████████▍| 4.93M/5.25M [00:14<00:00, 356kB/s]\n",
      " 95%|█████████▍| 4.97M/5.25M [00:14<00:00, 366kB/s]\n",
      " 95%|█████████▌| 5.01M/5.25M [00:14<00:00, 356kB/s]\n",
      " 96%|█████████▋| 5.05M/5.25M [00:15<00:00, 374kB/s]\n",
      " 97%|█████████▋| 5.09M/5.25M [00:15<00:00, 376kB/s]\n",
      " 98%|█████████▊| 5.13M/5.25M [00:15<00:00, 362kB/s]\n",
      " 99%|█████████▊| 5.17M/5.25M [00:15<00:00, 343kB/s]\n",
      " 99%|█████████▉| 5.21M/5.25M [00:15<00:00, 354kB/s]\n",
      "100%|██████████| 5.25M/5.25M [00:15<00:00, 336kB/s]\n",
      "100%|██████████| 5.25M/5.25M [00:17<00:00, 310kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit tabular-playground-series-nov-2021 -f {PATH_SUB+curr_submission_fn} -m {curr_submission_fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-10-14T20:08:15.118277+02:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.28.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 13, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm: 2.3.1\n",
      "pandas  : 1.0.5\n",
      "requests: 2.26.0\n",
      "sys     : 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
      "joblib  : 1.0.0\n",
      "catboost: 1.0.0\n",
      "xgboost : 1.1.1\n",
      "json    : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10ed364d45814f4af10e5aa088ae4ff654add15d6190d9b5a11312a81b7ebe3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
