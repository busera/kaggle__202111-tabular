{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad3779a",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfc11e",
   "metadata": {},
   "source": [
    "- Predicted score is very close to Kaggle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142084c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T03:53:23.806968Z",
     "iopub.status.busy": "2021-11-11T03:53:23.805417Z",
     "iopub.status.idle": "2021-11-11T03:53:29.701285Z",
     "shell.execute_reply": "2021-11-11T03:53:29.700641Z",
     "shell.execute_reply.started": "2021-11-11T03:37:47.602445Z"
    },
    "papermill": {
     "duration": 5.915222,
     "end_time": "2021-11-11T03:53:29.701454",
     "exception": false,
     "start_time": "2021-11-11T03:53:23.786232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The rest of the modules are loaded when required.\n",
    "# To ensure a standalone character (for easier reusability).\n",
    "\n",
    "import os # for detecting CPU cores\n",
    "import configparser # to load standard config and parameters\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209d47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs used: 16\n"
     ]
    }
   ],
   "source": [
    "# Load external config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../src/config.ini\")\n",
    "\n",
    "PATH_DATA_RAW = config[\"PATHS\"][\"PATH_DATA_RAW\"]\n",
    "PATH_DATA_INT = config[\"PATHS\"][\"PATH_DATA_INT\"]\n",
    "PATH_DATA_PRO = config[\"PATHS\"][\"PATH_DATA_PRO\"]\n",
    "PATH_REPORTS = config[\"PATHS\"][\"PATH_REPORTS\"]\n",
    "PATH_MODELS = config[\"PATHS\"][\"PATH_MODELS\"]\n",
    "PATH_SUB = config[\"PATHS\"][\"PATH_SUB\"]\n",
    "\n",
    "# Telegram Bot\n",
    "token = config[\"TELEGRAM\"][\"token\"]\n",
    "chat_id = config[\"TELEGRAM\"][\"chat_id\"]\n",
    "FILENAME_NB = \"02_baseline_models\" # for Telegram messages\n",
    "\n",
    "# Set global randome state\n",
    "rnd_state = 42\n",
    "\n",
    "# Define available cpu cores\n",
    "n_cpu = os.cpu_count()\n",
    "print(\"Number of CPUs used:\", n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f0fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Columns: 156 entries, f0 to target\n",
      "dtypes: float32(155), int8(1)\n",
      "memory usage: 355.3 MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 540000 entries, 0 to 539999\n",
      "Columns: 155 entries, f0 to cluster_poly46\n",
      "dtypes: float32(155)\n",
      "memory usage: 319.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_poly37</th>\n",
       "      <th>cluster_poly38</th>\n",
       "      <th>cluster_poly39</th>\n",
       "      <th>cluster_poly40</th>\n",
       "      <th>cluster_poly41</th>\n",
       "      <th>cluster_poly42</th>\n",
       "      <th>cluster_poly43</th>\n",
       "      <th>cluster_poly44</th>\n",
       "      <th>cluster_poly45</th>\n",
       "      <th>cluster_poly46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.414343</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.223129</td>\n",
       "      <td>0.219181</td>\n",
       "      <td>-0.549174</td>\n",
       "      <td>0.356604</td>\n",
       "      <td>-0.117173</td>\n",
       "      <td>-0.149785</td>\n",
       "      <td>-0.569723</td>\n",
       "      <td>...</td>\n",
       "      <td>6512.845215</td>\n",
       "      <td>6805.715820</td>\n",
       "      <td>13652.173828</td>\n",
       "      <td>10663.488281</td>\n",
       "      <td>4265.094238</td>\n",
       "      <td>8555.721680</td>\n",
       "      <td>6682.733398</td>\n",
       "      <td>8940.457031</td>\n",
       "      <td>6983.243652</td>\n",
       "      <td>14008.291992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073411</td>\n",
       "      <td>-0.324111</td>\n",
       "      <td>-0.220699</td>\n",
       "      <td>0.301799</td>\n",
       "      <td>0.406584</td>\n",
       "      <td>0.980651</td>\n",
       "      <td>-0.584290</td>\n",
       "      <td>-1.216782</td>\n",
       "      <td>0.824004</td>\n",
       "      <td>-0.258296</td>\n",
       "      <td>...</td>\n",
       "      <td>4172.796387</td>\n",
       "      <td>4559.007324</td>\n",
       "      <td>11665.178711</td>\n",
       "      <td>8874.093750</td>\n",
       "      <td>2205.772949</td>\n",
       "      <td>5643.933105</td>\n",
       "      <td>4293.529785</td>\n",
       "      <td>6166.304688</td>\n",
       "      <td>4690.915039</td>\n",
       "      <td>12002.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.165673</td>\n",
       "      <td>-0.391725</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>-0.178365</td>\n",
       "      <td>-0.372808</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>0.863859</td>\n",
       "      <td>0.518747</td>\n",
       "      <td>-0.268295</td>\n",
       "      <td>-0.021567</td>\n",
       "      <td>...</td>\n",
       "      <td>3554.209229</td>\n",
       "      <td>3881.383545</td>\n",
       "      <td>10787.007812</td>\n",
       "      <td>8026.498047</td>\n",
       "      <td>1839.628296</td>\n",
       "      <td>5112.631348</td>\n",
       "      <td>3804.254883</td>\n",
       "      <td>5583.262695</td>\n",
       "      <td>4154.446289</td>\n",
       "      <td>11545.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.301555</td>\n",
       "      <td>-0.872802</td>\n",
       "      <td>2.498527</td>\n",
       "      <td>-0.301544</td>\n",
       "      <td>-0.587486</td>\n",
       "      <td>-0.414987</td>\n",
       "      <td>-0.039545</td>\n",
       "      <td>0.787011</td>\n",
       "      <td>0.807039</td>\n",
       "      <td>0.794548</td>\n",
       "      <td>...</td>\n",
       "      <td>4730.939941</td>\n",
       "      <td>5049.254395</td>\n",
       "      <td>12155.591797</td>\n",
       "      <td>9210.494141</td>\n",
       "      <td>2632.450684</td>\n",
       "      <td>6337.370605</td>\n",
       "      <td>4801.931152</td>\n",
       "      <td>6763.771484</td>\n",
       "      <td>5125.021973</td>\n",
       "      <td>12337.995117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.272393</td>\n",
       "      <td>0.460876</td>\n",
       "      <td>0.086985</td>\n",
       "      <td>-0.197278</td>\n",
       "      <td>-0.465605</td>\n",
       "      <td>-0.192678</td>\n",
       "      <td>0.518429</td>\n",
       "      <td>-1.042825</td>\n",
       "      <td>0.356489</td>\n",
       "      <td>-0.301740</td>\n",
       "      <td>...</td>\n",
       "      <td>3570.980469</td>\n",
       "      <td>3988.572266</td>\n",
       "      <td>11142.793945</td>\n",
       "      <td>8272.177734</td>\n",
       "      <td>1762.070557</td>\n",
       "      <td>4922.661133</td>\n",
       "      <td>3654.481201</td>\n",
       "      <td>5498.319336</td>\n",
       "      <td>4081.837402</td>\n",
       "      <td>11403.347656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.023869  0.414343 -0.003178  0.223129  0.219181 -0.549174  0.356604   \n",
       "1  0.073411 -0.324111 -0.220699  0.301799  0.406584  0.980651 -0.584290   \n",
       "2 -0.165673 -0.391725  0.386256 -0.178365 -0.372808  0.210182  0.863859   \n",
       "3 -0.301555 -0.872802  2.498527 -0.301544 -0.587486 -0.414987 -0.039545   \n",
       "4 -0.272393  0.460876  0.086985 -0.197278 -0.465605 -0.192678  0.518429   \n",
       "\n",
       "         f7        f8        f9  ...  cluster_poly37  cluster_poly38  \\\n",
       "0 -0.117173 -0.149785 -0.569723  ...     6512.845215     6805.715820   \n",
       "1 -1.216782  0.824004 -0.258296  ...     4172.796387     4559.007324   \n",
       "2  0.518747 -0.268295 -0.021567  ...     3554.209229     3881.383545   \n",
       "3  0.787011  0.807039  0.794548  ...     4730.939941     5049.254395   \n",
       "4 -1.042825  0.356489 -0.301740  ...     3570.980469     3988.572266   \n",
       "\n",
       "   cluster_poly39  cluster_poly40  cluster_poly41  cluster_poly42  \\\n",
       "0    13652.173828    10663.488281     4265.094238     8555.721680   \n",
       "1    11665.178711     8874.093750     2205.772949     5643.933105   \n",
       "2    10787.007812     8026.498047     1839.628296     5112.631348   \n",
       "3    12155.591797     9210.494141     2632.450684     6337.370605   \n",
       "4    11142.793945     8272.177734     1762.070557     4922.661133   \n",
       "\n",
       "   cluster_poly43  cluster_poly44  cluster_poly45  cluster_poly46  \n",
       "0     6682.733398     8940.457031     6983.243652    14008.291992  \n",
       "1     4293.529785     6166.304688     4690.915039    12002.692383  \n",
       "2     3804.254883     5583.262695     4154.446289    11545.894531  \n",
       "3     4801.931152     6763.771484     5125.021973    12337.995117  \n",
       "4     3654.481201     5498.319336     4081.837402    11403.347656  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INTERIM OPT\n",
    "train_df = pd.read_pickle(PATH_DATA_INT+'train-opt-fe.pkl')\n",
    "test_df = pd.read_pickle(PATH_DATA_INT+'test-opt-fe.pkl')\n",
    "sample_df = pd.read_csv(PATH_DATA_RAW+'sample_submission.csv')\n",
    "\n",
    "# Memory Usage\n",
    "train_df.info(memory_usage=\"deep\")\n",
    "print()\n",
    "test_df.info(memory_usage=\"deep\")\n",
    "\n",
    "# Preparing features and target\n",
    "#features_num = train_df.drop(['id','target'], axis=1).columns\n",
    "features_num = train_df.drop(['target'], axis=1).columns\n",
    "feature_cols = features_num.to_list()\n",
    "\n",
    "#X = train_df.drop(['id','target'], axis=1).copy()\n",
    "#y = train_df['target'].copy()\n",
    "#X_test = test_df.drop(['id'], axis=1).copy()\n",
    "\n",
    "X = train_df.drop(['target'], axis=1).copy()\n",
    "y = train_df['target'].copy()\n",
    "X_test = test_df.copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ce0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling all values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# MinMaxScaler(feature_range = (0, 1)) will transform each value in the column proportionally within the range [0,1]. \n",
    "# Use this as the first scaler choice to transform a feature, as it will preserve the shape of the dataset \n",
    "# (no distortion).\n",
    "\n",
    "# StandardScaler() will transform each value in the column to range about the mean 0 and standard deviation 1, ie, \n",
    "# each value will be normalised by subtracting the mean and dividing by standard deviation. Use StandardScaler if \n",
    "# you know the data distribution is normal.\n",
    "\n",
    "# If there are outliers, use RobustScaler(). Alternatively you could remove the outliers and use either of the above \n",
    "# 2 scalers (choice depends on whether data is normally distributed)\n",
    "\n",
    "# Additional Note: If scaler is used before train_test_split, data leakage will happen. \n",
    "# Do use scaler after train_test_split\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler = RobustScaler()\n",
    "\n",
    "\"\"\"\n",
    "for col in feature_cols:\n",
    "    X[col] = s_scaler.fit_transform(np.array(X[col]).reshape(-1,1))\n",
    "    X_test[col] = s_scaler.transform(np.array(X_test[col]).reshape(-1,1))\n",
    "\"\"\"\n",
    "\n",
    "# train\n",
    "X_scaled = scaler.fit_transform(X[feature_cols])\n",
    "X = pd.DataFrame(X_scaled, columns=feature_cols, index=X.index)\n",
    "\n",
    "# test\n",
    "X_test_scaled = scaler.transform(X_test[feature_cols])\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02bae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_poly37</th>\n",
       "      <th>cluster_poly38</th>\n",
       "      <th>cluster_poly39</th>\n",
       "      <th>cluster_poly40</th>\n",
       "      <th>cluster_poly41</th>\n",
       "      <th>cluster_poly42</th>\n",
       "      <th>cluster_poly43</th>\n",
       "      <th>cluster_poly44</th>\n",
       "      <th>cluster_poly45</th>\n",
       "      <th>cluster_poly46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705772</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068591</td>\n",
       "      <td>1.013719</td>\n",
       "      <td>1.042430</td>\n",
       "      <td>1.026898</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>1.242489</td>\n",
       "      <td>1.153755</td>\n",
       "      <td>1.174762</td>\n",
       "      <td>1.095656</td>\n",
       "      <td>1.121353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417062</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090666</td>\n",
       "      <td>-0.112540</td>\n",
       "      <td>-0.069231</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>-0.139317</td>\n",
       "      <td>-0.126337</td>\n",
       "      <td>-0.090038</td>\n",
       "      <td>-0.160769</td>\n",
       "      <td>-0.114093</td>\n",
       "      <td>-0.072476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397113</td>\n",
       "      <td>-0.452229</td>\n",
       "      <td>-0.560540</td>\n",
       "      <td>-0.481067</td>\n",
       "      <td>-0.330431</td>\n",
       "      <td>-0.376101</td>\n",
       "      <td>-0.344750</td>\n",
       "      <td>-0.441457</td>\n",
       "      <td>-0.397208</td>\n",
       "      <td>-0.344384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185838</td>\n",
       "      <td>0.133217</td>\n",
       "      <td>0.205140</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.083393</td>\n",
       "      <td>0.199646</td>\n",
       "      <td>0.174630</td>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.115002</td>\n",
       "      <td>0.127113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388805</td>\n",
       "      <td>-0.398496</td>\n",
       "      <td>-0.361489</td>\n",
       "      <td>-0.340575</td>\n",
       "      <td>-0.370914</td>\n",
       "      <td>-0.465406</td>\n",
       "      <td>-0.422720</td>\n",
       "      <td>-0.482350</td>\n",
       "      <td>-0.435526</td>\n",
       "      <td>-0.429234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.382553  0.705772 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1 -0.347377 -0.530387 -0.417062  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2 -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3 -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4 -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "\n",
       "         f7        f8        f9  ...  cluster_poly37  cluster_poly38  \\\n",
       "0 -0.197064 -0.286162 -0.289270  ...        1.068591        1.013719   \n",
       "1 -1.963980  1.309644 -0.229122  ...       -0.090666       -0.112540   \n",
       "2  0.824771 -0.480372 -0.183401  ...       -0.397113       -0.452229   \n",
       "3  1.255833  1.281843 -0.025780  ...        0.185838        0.133217   \n",
       "4 -1.684456  0.543499 -0.237512  ...       -0.388805       -0.398496   \n",
       "\n",
       "   cluster_poly39  cluster_poly40  cluster_poly41  cluster_poly42  \\\n",
       "0        1.042430        1.026898        0.935574        1.242489   \n",
       "1       -0.069231        0.003631       -0.139317       -0.126337   \n",
       "2       -0.560540       -0.481067       -0.330431       -0.376101   \n",
       "3        0.205140        0.196002        0.083393        0.199646   \n",
       "4       -0.361489       -0.340575       -0.370914       -0.465406   \n",
       "\n",
       "   cluster_poly43  cluster_poly44  cluster_poly45  cluster_poly46  \n",
       "0        1.153755        1.174762        1.095656        1.121353  \n",
       "1       -0.090038       -0.160769       -0.114093       -0.072476  \n",
       "2       -0.344750       -0.441457       -0.397208       -0.344384  \n",
       "3        0.174630        0.126863        0.115002        0.127113  \n",
       "4       -0.422720       -0.482350       -0.435526       -0.429234  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0c8829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T03:53:56.874741Z",
     "iopub.status.busy": "2021-11-11T03:53:56.873726Z",
     "iopub.status.idle": "2021-11-11T03:53:59.925822Z",
     "shell.execute_reply": "2021-11-11T03:53:59.926798Z",
     "shell.execute_reply.started": "2021-11-11T03:38:06.501097Z"
    },
    "papermill": {
     "duration": 3.072229,
     "end_time": "2021-11-11T03:53:59.927013",
     "exception": false,
     "start_time": "2021-11-11T03:53:56.854784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(X)\n",
    "test = scaler.transform(X_test)\n",
    "target = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8e406",
   "metadata": {
    "papermill": {
     "duration": 0.023238,
     "end_time": "2021-11-11T03:53:59.972875",
     "exception": false,
     "start_time": "2021-11-11T03:53:59.949637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc56b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.backend import clear_session\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f364d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T03:54:00.026865Z",
     "iopub.status.busy": "2021-11-11T03:54:00.025960Z",
     "iopub.status.idle": "2021-11-11T03:54:00.030031Z",
     "shell.execute_reply": "2021-11-11T03:54:00.030603Z",
     "shell.execute_reply.started": "2021-11-11T03:38:09.482061Z"
    },
    "papermill": {
     "duration": 0.035908,
     "end_time": "2021-11-11T03:54:00.030804",
     "exception": false,
     "start_time": "2021-11-11T03:53:59.994896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_cnn(units, dim, optimizer, kernel_initializer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(units, 2, activation=\"swish\", input_shape=(dim,1)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(units, 2, activation=\"swish\", input_shape=(dim,1)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units, activation=\"relu\"))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['AUC'])    \n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97cfa26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T03:54:00.100611Z",
     "iopub.status.busy": "2021-11-11T03:54:00.099756Z",
     "iopub.status.idle": "2021-11-11T03:54:00.111634Z",
     "shell.execute_reply": "2021-11-11T03:54:00.112614Z",
     "shell.execute_reply.started": "2021-11-11T03:44:29.492495Z"
    },
    "papermill": {
     "duration": 0.060074,
     "end_time": "2021-11-11T03:54:00.112823",
     "exception": false,
     "start_time": "2021-11-11T03:54:00.052749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(units, dim, optimizer, kernel_initializer):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish', input_dim = dim))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = units, activation = 'swish'))\n",
    "    model.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['AUC'])\n",
    "    return model    \n",
    "\n",
    "lr = ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=5, verbose=1)\n",
    "es = EarlyStopping(monitor=\"val_auc\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291e64bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T03:54:00.193357Z",
     "iopub.status.busy": "2021-11-11T03:54:00.192541Z",
     "iopub.status.idle": "2021-11-11T04:15:05.992872Z",
     "shell.execute_reply": "2021-11-11T04:15:05.993326Z",
     "shell.execute_reply.started": "2021-11-11T03:44:33.459977Z"
    },
    "papermill": {
     "duration": 1265.83623,
     "end_time": "2021-11-11T04:15:05.993506",
     "exception": false,
     "start_time": "2021-11-11T03:54:00.157276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- > Fold 0 < ---------------\n",
      "Epoch 1/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.6056 - auc: 0.7292 - val_loss: 0.5759 - val_auc: 0.7456 - lr: 0.0012\n",
      "Epoch 2/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5777 - auc: 0.7453 - val_loss: 0.5737 - val_auc: 0.7456 - lr: 0.0012\n",
      "Epoch 3/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5745 - auc: 0.7470 - val_loss: 0.5755 - val_auc: 0.7436 - lr: 0.0012\n",
      "Epoch 4/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5731 - auc: 0.7477 - val_loss: 0.5736 - val_auc: 0.7451 - lr: 0.0012\n",
      "Epoch 5/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5724 - auc: 0.7480 - val_loss: 0.5731 - val_auc: 0.7461 - lr: 0.0012\n",
      "Epoch 6/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5717 - auc: 0.7480 - val_loss: 0.5760 - val_auc: 0.7443 - lr: 0.0012\n",
      "Epoch 7/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5713 - auc: 0.7481 - val_loss: 0.5709 - val_auc: 0.7462 - lr: 0.0012\n",
      "Epoch 8/40\n",
      "1750/1758 [============================>.] - ETA: 0s - loss: 0.5712 - auc: 0.7485\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006150000263005495.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5711 - auc: 0.7485 - val_loss: 0.5725 - val_auc: 0.7462 - lr: 0.0012\n",
      "Epoch 9/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5683 - auc: 0.7492 - val_loss: 0.5705 - val_auc: 0.7453 - lr: 6.1500e-04\n",
      "Epoch 10/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5682 - auc: 0.7491 - val_loss: 0.5708 - val_auc: 0.7455 - lr: 6.1500e-04\n",
      "Epoch 11/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5678 - auc: 0.7494 - val_loss: 0.5698 - val_auc: 0.7456 - lr: 6.1500e-04\n",
      "Epoch 12/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5676 - auc: 0.7495 - val_loss: 0.5702 - val_auc: 0.7455 - lr: 6.1500e-04\n",
      "Epoch 13/40\n",
      "1745/1758 [============================>.] - ETA: 0s - loss: 0.5675 - auc: 0.7493\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00030750001315027475.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5674 - auc: 0.7494 - val_loss: 0.5694 - val_auc: 0.7468 - lr: 6.1500e-04\n",
      "Epoch 14/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5660 - auc: 0.7501 - val_loss: 0.5683 - val_auc: 0.7460 - lr: 3.0750e-04\n",
      "Epoch 15/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5657 - auc: 0.7495 - val_loss: 0.5696 - val_auc: 0.7461 - lr: 3.0750e-04\n",
      "Epoch 16/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5654 - auc: 0.7509 - val_loss: 0.5686 - val_auc: 0.7466 - lr: 3.0750e-04\n",
      "Epoch 17/40\n",
      "1758/1758 [==============================] - 6s 4ms/step - loss: 0.5654 - auc: 0.7502 - val_loss: 0.5687 - val_auc: 0.7463 - lr: 3.0750e-04\n",
      "Epoch 18/40\n",
      "1755/1758 [============================>.] - ETA: 0s - loss: 0.5655 - auc: 0.7501\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00015375000657513738.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5654 - auc: 0.7501 - val_loss: 0.5686 - val_auc: 0.7463 - lr: 3.0750e-04\n",
      "Epoch 19/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5645 - auc: 0.7508 - val_loss: 0.5685 - val_auc: 0.7458 - lr: 1.5375e-04\n",
      "Epoch 20/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5643 - auc: 0.7506 - val_loss: 0.5685 - val_auc: 0.7459 - lr: 1.5375e-04\n",
      "Epoch 21/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5642 - auc: 0.7505 - val_loss: 0.5684 - val_auc: 0.7454 - lr: 1.5375e-04\n",
      "Epoch 22/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5643 - auc: 0.7504 - val_loss: 0.5684 - val_auc: 0.7457 - lr: 1.5375e-04\n",
      "Epoch 23/40\n",
      "1748/1758 [============================>.] - ETA: 0s - loss: 0.5642 - auc: 0.7509\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.687500328756869e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7510 - val_loss: 0.5682 - val_auc: 0.7459 - lr: 1.5375e-04\n",
      "Epoch 24/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5637 - auc: 0.7510 - val_loss: 0.5678 - val_auc: 0.7462 - lr: 7.6875e-05\n",
      "Epoch 25/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5636 - auc: 0.7516 - val_loss: 0.5680 - val_auc: 0.7461 - lr: 7.6875e-05\n",
      "Epoch 26/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5635 - auc: 0.7514 - val_loss: 0.5681 - val_auc: 0.7458 - lr: 7.6875e-05\n",
      "Epoch 27/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5635 - auc: 0.7518 - val_loss: 0.5680 - val_auc: 0.7459 - lr: 7.6875e-05\n",
      "Epoch 28/40\n",
      "1748/1758 [============================>.] - ETA: 0s - loss: 0.5635 - auc: 0.7513\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.8437501643784344e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5636 - auc: 0.7513 - val_loss: 0.5682 - val_auc: 0.7455 - lr: 7.6875e-05\n",
      "Epoch 29/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5633 - auc: 0.7518 - val_loss: 0.5681 - val_auc: 0.7453 - lr: 3.8438e-05\n",
      "Epoch 30/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5632 - auc: 0.7508 - val_loss: 0.5680 - val_auc: 0.7458 - lr: 3.8438e-05\n",
      "Epoch 31/40\n",
      "1758/1758 [==============================] - 6s 4ms/step - loss: 0.5632 - auc: 0.7519 - val_loss: 0.5679 - val_auc: 0.7453 - lr: 3.8438e-05\n",
      "Epoch 32/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5631 - auc: 0.7521 - val_loss: 0.5680 - val_auc: 0.7457 - lr: 3.8438e-05\n",
      "Epoch 33/40\n",
      "1752/1758 [============================>.] - ETA: 0s - loss: 0.5631 - auc: 0.7519\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.9218750821892172e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5631 - auc: 0.7519 - val_loss: 0.5680 - val_auc: 0.7456 - lr: 3.8438e-05\n",
      "Epoch 34/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5631 - auc: 0.7517 - val_loss: 0.5679 - val_auc: 0.7460 - lr: 1.9219e-05\n",
      "Epoch 35/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5630 - auc: 0.7516 - val_loss: 0.5679 - val_auc: 0.7457 - lr: 1.9219e-05\n",
      "Epoch 36/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5629 - auc: 0.7516 - val_loss: 0.5679 - val_auc: 0.7459 - lr: 1.9219e-05\n",
      "Epoch 37/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5630 - auc: 0.7518 - val_loss: 0.5679 - val_auc: 0.7459 - lr: 1.9219e-05\n",
      "Epoch 38/40\n",
      "1749/1758 [============================>.] - ETA: 0s - loss: 0.5630 - auc: 0.7512\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.609375410946086e-06.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5629 - auc: 0.7513 - val_loss: 0.5678 - val_auc: 0.7457 - lr: 1.9219e-05\n",
      "Epoch 39/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5630 - auc: 0.7518 - val_loss: 0.5678 - val_auc: 0.7456 - lr: 9.6094e-06\n",
      "Epoch 40/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5629 - auc: 0.7523 - val_loss: 0.5678 - val_auc: 0.7457 - lr: 9.6094e-06\n",
      "--------------- > Fold 1 < ---------------\n",
      "Epoch 1/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.6073 - auc: 0.7276 - val_loss: 0.5789 - val_auc: 0.7442 - lr: 0.0012\n",
      "Epoch 2/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5777 - auc: 0.7455 - val_loss: 0.5773 - val_auc: 0.7446 - lr: 0.0012\n",
      "Epoch 3/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5748 - auc: 0.7464 - val_loss: 0.5735 - val_auc: 0.7450 - lr: 0.0012\n",
      "Epoch 4/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5734 - auc: 0.7467 - val_loss: 0.5714 - val_auc: 0.7463 - lr: 0.0012\n",
      "Epoch 5/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5727 - auc: 0.7475 - val_loss: 0.5736 - val_auc: 0.7453 - lr: 0.0012\n",
      "Epoch 6/40\n",
      "1751/1758 [============================>.] - ETA: 0s - loss: 0.5721 - auc: 0.7474\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006150000263005495.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5721 - auc: 0.7475 - val_loss: 0.5712 - val_auc: 0.7465 - lr: 0.0012\n",
      "Epoch 7/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5693 - auc: 0.7482 - val_loss: 0.5695 - val_auc: 0.7467 - lr: 6.1500e-04\n",
      "Epoch 8/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5686 - auc: 0.7485 - val_loss: 0.5696 - val_auc: 0.7475 - lr: 6.1500e-04\n",
      "Epoch 9/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5686 - auc: 0.7486 - val_loss: 0.5685 - val_auc: 0.7479 - lr: 6.1500e-04\n",
      "Epoch 10/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5684 - auc: 0.7485 - val_loss: 0.5684 - val_auc: 0.7472 - lr: 6.1500e-04\n",
      "Epoch 11/40\n",
      "1749/1758 [============================>.] - ETA: 0s - loss: 0.5679 - auc: 0.7487\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00030750001315027475.\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5679 - auc: 0.7486 - val_loss: 0.5696 - val_auc: 0.7478 - lr: 6.1500e-04\n",
      "Epoch 12/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5665 - auc: 0.7502 - val_loss: 0.5679 - val_auc: 0.7482 - lr: 3.0750e-04\n",
      "Epoch 13/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5663 - auc: 0.7497 - val_loss: 0.5681 - val_auc: 0.7479 - lr: 3.0750e-04\n",
      "Epoch 14/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5662 - auc: 0.7493 - val_loss: 0.5680 - val_auc: 0.7483 - lr: 3.0750e-04\n",
      "Epoch 15/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5660 - auc: 0.7499 - val_loss: 0.5677 - val_auc: 0.7487 - lr: 3.0750e-04\n",
      "Epoch 16/40\n",
      "1751/1758 [============================>.] - ETA: 0s - loss: 0.5659 - auc: 0.7497\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00015375000657513738.\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5660 - auc: 0.7496 - val_loss: 0.5686 - val_auc: 0.7475 - lr: 3.0750e-04\n",
      "Epoch 17/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5651 - auc: 0.7501 - val_loss: 0.5677 - val_auc: 0.7477 - lr: 1.5375e-04\n",
      "Epoch 18/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5649 - auc: 0.7500 - val_loss: 0.5674 - val_auc: 0.7477 - lr: 1.5375e-04\n",
      "Epoch 19/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5649 - auc: 0.7499 - val_loss: 0.5672 - val_auc: 0.7482 - lr: 1.5375e-04\n",
      "Epoch 20/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5648 - auc: 0.7502 - val_loss: 0.5672 - val_auc: 0.7485 - lr: 1.5375e-04\n",
      "Epoch 21/40\n",
      "1750/1758 [============================>.] - ETA: 0s - loss: 0.5647 - auc: 0.7510\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.687500328756869e-05.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5647 - auc: 0.7510 - val_loss: 0.5674 - val_auc: 0.7487 - lr: 1.5375e-04\n",
      "Epoch 22/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5643 - auc: 0.7505 - val_loss: 0.5670 - val_auc: 0.7481 - lr: 7.6875e-05\n",
      "Epoch 23/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5642 - auc: 0.7507 - val_loss: 0.5671 - val_auc: 0.7485 - lr: 7.6875e-05\n",
      "Epoch 24/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5641 - auc: 0.7513 - val_loss: 0.5671 - val_auc: 0.7477 - lr: 7.6875e-05\n",
      "Epoch 25/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5641 - auc: 0.7506 - val_loss: 0.5670 - val_auc: 0.7483 - lr: 7.6875e-05\n",
      "Epoch 26/40\n",
      "1748/1758 [============================>.] - ETA: 0s - loss: 0.5641 - auc: 0.7508\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.8437501643784344e-05.\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5640 - auc: 0.7508 - val_loss: 0.5672 - val_auc: 0.7485 - lr: 7.6875e-05\n",
      "Epoch 27/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5637 - auc: 0.7514 - val_loss: 0.5669 - val_auc: 0.7484 - lr: 3.8438e-05\n",
      "Epoch 28/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5637 - auc: 0.7511 - val_loss: 0.5669 - val_auc: 0.7480 - lr: 3.8438e-05\n",
      "Epoch 29/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5637 - auc: 0.7516 - val_loss: 0.5670 - val_auc: 0.7483 - lr: 3.8438e-05\n",
      "Epoch 30/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5638 - auc: 0.7510 - val_loss: 0.5669 - val_auc: 0.7484 - lr: 3.8438e-05\n",
      "Epoch 31/40\n",
      "1754/1758 [============================>.] - ETA: 0s - loss: 0.5637 - auc: 0.7511\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.9218750821892172e-05.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5637 - auc: 0.7511 - val_loss: 0.5669 - val_auc: 0.7485 - lr: 3.8438e-05\n",
      "Epoch 32/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5635 - auc: 0.7517 - val_loss: 0.5669 - val_auc: 0.7482 - lr: 1.9219e-05\n",
      "Epoch 33/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5636 - auc: 0.7511 - val_loss: 0.5669 - val_auc: 0.7483 - lr: 1.9219e-05\n",
      "Epoch 34/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5635 - auc: 0.7511 - val_loss: 0.5669 - val_auc: 0.7480 - lr: 1.9219e-05\n",
      "Epoch 35/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5635 - auc: 0.7516 - val_loss: 0.5668 - val_auc: 0.7482 - lr: 1.9219e-05\n",
      "Epoch 36/40\n",
      "1751/1758 [============================>.] - ETA: 0s - loss: 0.5634 - auc: 0.7521\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.609375410946086e-06.\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5634 - auc: 0.7521 - val_loss: 0.5669 - val_auc: 0.7488 - lr: 1.9219e-05\n",
      "Epoch 37/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5634 - auc: 0.7512 - val_loss: 0.5669 - val_auc: 0.7483 - lr: 9.6094e-06\n",
      "Epoch 38/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5634 - auc: 0.7516 - val_loss: 0.5670 - val_auc: 0.7485 - lr: 9.6094e-06\n",
      "Epoch 39/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5635 - auc: 0.7517 - val_loss: 0.5669 - val_auc: 0.7484 - lr: 9.6094e-06\n",
      "Epoch 40/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5634 - auc: 0.7518 - val_loss: 0.5668 - val_auc: 0.7482 - lr: 9.6094e-06\n",
      "--------------- > Fold 2 < ---------------\n",
      "Epoch 1/40\n",
      "1758/1758 [==============================] - 10s 5ms/step - loss: 0.6050 - auc: 0.7294 - val_loss: 0.5748 - val_auc: 0.7482 - lr: 0.0012\n",
      "Epoch 2/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5780 - auc: 0.7446 - val_loss: 0.5699 - val_auc: 0.7487 - lr: 0.0012\n",
      "Epoch 3/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5754 - auc: 0.7459 - val_loss: 0.5697 - val_auc: 0.7491 - lr: 0.0012\n",
      "Epoch 4/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5746 - auc: 0.7464 - val_loss: 0.5704 - val_auc: 0.7490 - lr: 0.0012\n",
      "Epoch 5/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5733 - auc: 0.7465 - val_loss: 0.5700 - val_auc: 0.7493 - lr: 0.0012\n",
      "Epoch 6/40\n",
      "1749/1758 [============================>.] - ETA: 0s - loss: 0.5731 - auc: 0.7471\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006150000263005495.\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5732 - auc: 0.7471 - val_loss: 0.5682 - val_auc: 0.7505 - lr: 0.0012\n",
      "Epoch 7/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5701 - auc: 0.7476 - val_loss: 0.5661 - val_auc: 0.7502 - lr: 6.1500e-04\n",
      "Epoch 8/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5695 - auc: 0.7482 - val_loss: 0.5679 - val_auc: 0.7502 - lr: 6.1500e-04\n",
      "Epoch 9/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5695 - auc: 0.7479 - val_loss: 0.5670 - val_auc: 0.7495 - lr: 6.1500e-04\n",
      "Epoch 10/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5692 - auc: 0.7484 - val_loss: 0.5679 - val_auc: 0.7487 - lr: 6.1500e-04\n",
      "Epoch 11/40\n",
      "1753/1758 [============================>.] - ETA: 0s - loss: 0.5690 - auc: 0.7486\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00030750001315027475.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5690 - auc: 0.7486 - val_loss: 0.5670 - val_auc: 0.7500 - lr: 6.1500e-04\n",
      "Epoch 12/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5673 - auc: 0.7491 - val_loss: 0.5654 - val_auc: 0.7500 - lr: 3.0750e-04\n",
      "Epoch 13/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5670 - auc: 0.7487 - val_loss: 0.5651 - val_auc: 0.7503 - lr: 3.0750e-04\n",
      "Epoch 14/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5668 - auc: 0.7490 - val_loss: 0.5653 - val_auc: 0.7499 - lr: 3.0750e-04\n",
      "Epoch 15/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5669 - auc: 0.7492 - val_loss: 0.5655 - val_auc: 0.7498 - lr: 3.0750e-04\n",
      "Epoch 16/40\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5666 - auc: 0.7498\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00015375000657513738.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5666 - auc: 0.7498 - val_loss: 0.5658 - val_auc: 0.7505 - lr: 3.0750e-04\n",
      "Epoch 17/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5658 - auc: 0.7501 - val_loss: 0.5648 - val_auc: 0.7501 - lr: 1.5375e-04\n",
      "Epoch 18/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5656 - auc: 0.7496 - val_loss: 0.5649 - val_auc: 0.7501 - lr: 1.5375e-04\n",
      "Epoch 19/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5656 - auc: 0.7502 - val_loss: 0.5649 - val_auc: 0.7501 - lr: 1.5375e-04\n",
      "Epoch 20/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5655 - auc: 0.7499 - val_loss: 0.5650 - val_auc: 0.7498 - lr: 1.5375e-04\n",
      "Epoch 21/40\n",
      "1750/1758 [============================>.] - ETA: 0s - loss: 0.5655 - auc: 0.7499\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.687500328756869e-05.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5656 - auc: 0.7498 - val_loss: 0.5647 - val_auc: 0.7500 - lr: 1.5375e-04\n",
      "Epoch 22/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5649 - auc: 0.7501 - val_loss: 0.5649 - val_auc: 0.7500 - lr: 7.6875e-05\n",
      "Epoch 23/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5648 - auc: 0.7503 - val_loss: 0.5645 - val_auc: 0.7500 - lr: 7.6875e-05\n",
      "Epoch 24/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5647 - auc: 0.7505 - val_loss: 0.5649 - val_auc: 0.7498 - lr: 7.6875e-05\n",
      "Epoch 25/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5646 - auc: 0.7508 - val_loss: 0.5649 - val_auc: 0.7495 - lr: 7.6875e-05\n",
      "Epoch 26/40\n",
      "1748/1758 [============================>.] - ETA: 0s - loss: 0.5648 - auc: 0.7500\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.8437501643784344e-05.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5648 - auc: 0.7500 - val_loss: 0.5648 - val_auc: 0.7506 - lr: 7.6875e-05\n",
      "Epoch 27/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5645 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7500 - lr: 3.8438e-05\n",
      "Epoch 28/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5644 - auc: 0.7506 - val_loss: 0.5647 - val_auc: 0.7499 - lr: 3.8438e-05\n",
      "Epoch 29/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5643 - auc: 0.7510 - val_loss: 0.5645 - val_auc: 0.7498 - lr: 3.8438e-05\n",
      "Epoch 30/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5644 - auc: 0.7508 - val_loss: 0.5646 - val_auc: 0.7507 - lr: 3.8438e-05\n",
      "Epoch 31/40\n",
      "1749/1758 [============================>.] - ETA: 0s - loss: 0.5642 - auc: 0.7511\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.9218750821892172e-05.\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5642 - auc: 0.7511 - val_loss: 0.5646 - val_auc: 0.7506 - lr: 3.8438e-05\n",
      "Epoch 32/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5642 - auc: 0.7505 - val_loss: 0.5647 - val_auc: 0.7501 - lr: 1.9219e-05\n",
      "Epoch 33/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5642 - auc: 0.7504 - val_loss: 0.5648 - val_auc: 0.7502 - lr: 1.9219e-05\n",
      "Epoch 34/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5642 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7504 - lr: 1.9219e-05\n",
      "Epoch 35/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5642 - auc: 0.7512 - val_loss: 0.5645 - val_auc: 0.7501 - lr: 1.9219e-05\n",
      "Epoch 36/40\n",
      "1749/1758 [============================>.] - ETA: 0s - loss: 0.5641 - auc: 0.7506\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.609375410946086e-06.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7506 - val_loss: 0.5645 - val_auc: 0.7501 - lr: 1.9219e-05\n",
      "Epoch 37/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5640 - auc: 0.7510 - val_loss: 0.5645 - val_auc: 0.7501 - lr: 9.6094e-06\n",
      "Epoch 38/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5641 - auc: 0.7509 - val_loss: 0.5645 - val_auc: 0.7499 - lr: 9.6094e-06\n",
      "Epoch 39/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5641 - auc: 0.7509 - val_loss: 0.5645 - val_auc: 0.7501 - lr: 9.6094e-06\n",
      "Epoch 40/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5640 - auc: 0.7509 - val_loss: 0.5645 - val_auc: 0.7499 - lr: 9.6094e-06\n",
      "--------------- > Fold 3 < ---------------\n",
      "Epoch 1/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.6114 - auc: 0.7234 - val_loss: 0.5775 - val_auc: 0.7440 - lr: 0.0012\n",
      "Epoch 2/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5783 - auc: 0.7450 - val_loss: 0.5710 - val_auc: 0.7492 - lr: 0.0012\n",
      "Epoch 3/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5757 - auc: 0.7459 - val_loss: 0.5702 - val_auc: 0.7492 - lr: 0.0012\n",
      "Epoch 4/40\n",
      "1758/1758 [==============================] - 8s 5ms/step - loss: 0.5744 - auc: 0.7460 - val_loss: 0.5715 - val_auc: 0.7465 - lr: 0.0012\n",
      "Epoch 5/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5735 - auc: 0.7463 - val_loss: 0.5699 - val_auc: 0.7496 - lr: 0.0012\n",
      "Epoch 6/40\n",
      "1752/1758 [============================>.] - ETA: 0s - loss: 0.5729 - auc: 0.7466\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006150000263005495.\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5729 - auc: 0.7466 - val_loss: 0.5687 - val_auc: 0.7488 - lr: 0.0012\n",
      "Epoch 7/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5698 - auc: 0.7474 - val_loss: 0.5676 - val_auc: 0.7497 - lr: 6.1500e-04\n",
      "Epoch 8/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5694 - auc: 0.7481 - val_loss: 0.5669 - val_auc: 0.7503 - lr: 6.1500e-04\n",
      "Epoch 9/40\n",
      "1758/1758 [==============================] - 9s 5ms/step - loss: 0.5692 - auc: 0.7479 - val_loss: 0.5669 - val_auc: 0.7490 - lr: 6.1500e-04\n",
      "Epoch 10/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5690 - auc: 0.7477 - val_loss: 0.5663 - val_auc: 0.7504 - lr: 6.1500e-04\n",
      "Epoch 11/40\n",
      "1750/1758 [============================>.] - ETA: 0s - loss: 0.5689 - auc: 0.7479\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00030750001315027475.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5689 - auc: 0.7479 - val_loss: 0.5679 - val_auc: 0.7483 - lr: 6.1500e-04\n",
      "Epoch 12/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5672 - auc: 0.7483 - val_loss: 0.5657 - val_auc: 0.7496 - lr: 3.0750e-04\n",
      "Epoch 13/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5670 - auc: 0.7491 - val_loss: 0.5651 - val_auc: 0.7495 - lr: 3.0750e-04\n",
      "Epoch 14/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5669 - auc: 0.7487 - val_loss: 0.5654 - val_auc: 0.7502 - lr: 3.0750e-04\n",
      "Epoch 15/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5667 - auc: 0.7483 - val_loss: 0.5654 - val_auc: 0.7501 - lr: 3.0750e-04\n",
      "Epoch 16/40\n",
      "1746/1758 [============================>.] - ETA: 0s - loss: 0.5667 - auc: 0.7489\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00015375000657513738.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5667 - auc: 0.7489 - val_loss: 0.5656 - val_auc: 0.7497 - lr: 3.0750e-04\n",
      "Epoch 17/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5657 - auc: 0.7494 - val_loss: 0.5651 - val_auc: 0.7498 - lr: 1.5375e-04\n",
      "Epoch 18/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5657 - auc: 0.7488 - val_loss: 0.5647 - val_auc: 0.7495 - lr: 1.5375e-04\n",
      "Epoch 19/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5654 - auc: 0.7500 - val_loss: 0.5647 - val_auc: 0.7501 - lr: 1.5375e-04\n",
      "Epoch 20/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5653 - auc: 0.7493 - val_loss: 0.5650 - val_auc: 0.7498 - lr: 1.5375e-04\n",
      "Epoch 21/40\n",
      "1747/1758 [============================>.] - ETA: 0s - loss: 0.5654 - auc: 0.7500\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.687500328756869e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5654 - auc: 0.7501 - val_loss: 0.5651 - val_auc: 0.7496 - lr: 1.5375e-04\n",
      "Epoch 22/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5650 - auc: 0.7494 - val_loss: 0.5646 - val_auc: 0.7504 - lr: 7.6875e-05\n",
      "Epoch 23/40\n",
      "1758/1758 [==============================] - 6s 4ms/step - loss: 0.5647 - auc: 0.7504 - val_loss: 0.5646 - val_auc: 0.7496 - lr: 7.6875e-05\n",
      "Epoch 24/40\n",
      "1758/1758 [==============================] - 6s 4ms/step - loss: 0.5648 - auc: 0.7500 - val_loss: 0.5646 - val_auc: 0.7495 - lr: 7.6875e-05\n",
      "Epoch 25/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5647 - auc: 0.7505 - val_loss: 0.5647 - val_auc: 0.7495 - lr: 7.6875e-05\n",
      "Epoch 26/40\n",
      "1757/1758 [============================>.] - ETA: 0s - loss: 0.5646 - auc: 0.7498\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.8437501643784344e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5646 - auc: 0.7498 - val_loss: 0.5649 - val_auc: 0.7495 - lr: 7.6875e-05\n",
      "Epoch 27/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5644 - auc: 0.7504 - val_loss: 0.5646 - val_auc: 0.7495 - lr: 3.8438e-05\n",
      "Epoch 28/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5643 - auc: 0.7500 - val_loss: 0.5648 - val_auc: 0.7495 - lr: 3.8438e-05\n",
      "Epoch 29/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5644 - auc: 0.7501 - val_loss: 0.5646 - val_auc: 0.7500 - lr: 3.8438e-05\n",
      "Epoch 30/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5644 - auc: 0.7506 - val_loss: 0.5646 - val_auc: 0.7497 - lr: 3.8438e-05\n",
      "Epoch 31/40\n",
      "1752/1758 [============================>.] - ETA: 0s - loss: 0.5644 - auc: 0.7506\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.9218750821892172e-05.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5643 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7498 - lr: 3.8438e-05\n",
      "Epoch 32/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5642 - auc: 0.7501 - val_loss: 0.5645 - val_auc: 0.7494 - lr: 1.9219e-05\n",
      "Epoch 33/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7500 - lr: 1.9219e-05\n",
      "Epoch 34/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7502 - val_loss: 0.5645 - val_auc: 0.7496 - lr: 1.9219e-05\n",
      "Epoch 35/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7506 - val_loss: 0.5646 - val_auc: 0.7494 - lr: 1.9219e-05\n",
      "Epoch 36/40\n",
      "1746/1758 [============================>.] - ETA: 0s - loss: 0.5641 - auc: 0.7504\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.609375410946086e-06.\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5641 - auc: 0.7505 - val_loss: 0.5645 - val_auc: 0.7499 - lr: 1.9219e-05\n",
      "Epoch 37/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5640 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7494 - lr: 9.6094e-06\n",
      "Epoch 38/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5640 - auc: 0.7503 - val_loss: 0.5645 - val_auc: 0.7487 - lr: 9.6094e-06\n",
      "Epoch 39/40\n",
      "1758/1758 [==============================] - 8s 4ms/step - loss: 0.5640 - auc: 0.7511 - val_loss: 0.5645 - val_auc: 0.7498 - lr: 9.6094e-06\n",
      "Epoch 40/40\n",
      "1758/1758 [==============================] - 7s 4ms/step - loss: 0.5640 - auc: 0.7507 - val_loss: 0.5645 - val_auc: 0.7497 - lr: 9.6094e-06\n"
     ]
    }
   ],
   "source": [
    "UNITS = 32\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 256\n",
    "TOTAL_SPLITS = 4\n",
    "LEARNING_RATE = 0.00123\n",
    "CNN = False\n",
    "\n",
    "\n",
    "if CNN:\n",
    "    train = train.reshape(train.shape[0], train.shape[1], 1)\n",
    "    test = test.reshape(test.shape[0], test.shape[1], 1)\n",
    "\n",
    "\n",
    "models = []\n",
    "histories = []\n",
    "folds = StratifiedKFold(n_splits=TOTAL_SPLITS, shuffle=True, random_state=rnd_state)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train, target)):\n",
    "    clear_session()\n",
    "    gc.collect()\n",
    "    print('-'*15, '>', f'Fold {fold_n}', '<', '-'*15)\n",
    "    X_train, X_valid = train[train_index], train[valid_index]\n",
    "    y_train, y_valid = target[train_index], target[valid_index]    \n",
    "    \n",
    "    if CNN:\n",
    "        model = create_model_cnn(UNITS, train.shape[1], keras.optimizers.Adam(learning_rate=LEARNING_RATE), 'glorot_uniform')\n",
    "    else:\n",
    "        model = create_model(UNITS, train.shape[1], keras.optimizers.Adam(learning_rate=LEARNING_RATE), 'glorot_uniform')\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size = BATCH_SIZE, epochs = EPOCHS, \n",
    "                    verbose=1, shuffle=True, callbacks=[lr, es])\n",
    "    models.append(model)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7750c0",
   "metadata": {
    "papermill": {
     "duration": 5.250617,
     "end_time": "2021-11-11T04:15:16.227449",
     "exception": false,
     "start_time": "2021-11-11T04:15:10.976832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting metrics recorded during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afcde9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T04:15:26.108560Z",
     "iopub.status.busy": "2021-11-11T04:15:26.107667Z",
     "iopub.status.idle": "2021-11-11T04:15:26.575651Z",
     "shell.execute_reply": "2021-11-11T04:15:26.577472Z",
     "shell.execute_reply.started": "2021-11-11T03:20:43.950868Z"
    },
    "papermill": {
     "duration": 5.4169,
     "end_time": "2021-11-11T04:15:26.577820",
     "exception": false,
     "start_time": "2021-11-11T04:15:21.160920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "history = histories[0]\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='center right')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e74f0c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467543482780457"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(history.history['val_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e6c98",
   "metadata": {
    "papermill": {
     "duration": 5.058227,
     "end_time": "2021-11-11T04:15:37.250917",
     "exception": false,
     "start_time": "2021-11-11T04:15:32.192690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea1110e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T04:15:47.457205Z",
     "iopub.status.busy": "2021-11-11T04:15:47.456249Z",
     "iopub.status.idle": "2021-11-11T04:17:07.101094Z",
     "shell.execute_reply": "2021-11-11T04:17:07.100537Z",
     "shell.execute_reply.started": "2021-11-10T23:02:59.075046Z"
    },
    "papermill": {
     "duration": 84.544664,
     "end_time": "2021-11-11T04:17:07.101242",
     "exception": false,
     "start_time": "2021-11-11T04:15:42.556578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = []\n",
    "for model in models:\n",
    "    predicted.append(model.predict(test))\n",
    "\n",
    "avg_preds = np.zeros(len(predicted[0]))\n",
    "for pred in predicted:\n",
    "    avg_preds += pred.ravel()\n",
    "avg_pred = avg_preds / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c6e777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T04:17:17.816875Z",
     "iopub.status.busy": "2021-11-11T04:17:17.816047Z",
     "iopub.status.idle": "2021-11-11T04:17:19.840090Z",
     "shell.execute_reply": "2021-11-11T04:17:19.839567Z",
     "shell.execute_reply.started": "2021-11-10T23:04:17.41021Z"
    },
    "papermill": {
     "duration": 7.24429,
     "end_time": "2021-11-11T04:17:19.840222",
     "exception": false,
     "start_time": "2021-11-11T04:17:12.595932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.741833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.740295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.744158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.246080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.739952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  600000  0.741833\n",
       "1  600001  0.740295\n",
       "2  600002  0.744158\n",
       "3  600003  0.246080\n",
       "4  600004  0.739952"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['target'] = avg_pred\n",
    "sample_df['id'] = sample_df['id'].astype(int)\n",
    "sample_df.to_csv('submission.csv', index=False, float_format='%.6f')\n",
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe1f9c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          int32\n",
       "target    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f34f4d",
   "metadata": {},
   "source": [
    "- train-opt: VAL AUC: 0.7473278641700745 | Kaggle: 0.74735\n",
    "- train-opt-fe: 0.7467543482780457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f706f30",
   "metadata": {
    "papermill": {
     "duration": 5.132249,
     "end_time": "2021-11-11T04:17:29.868054",
     "exception": false,
     "start_time": "2021-11-11T04:17:24.735805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit tabular-playground-series-nov-2021 -f submission.csv -m ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1461.546301,
   "end_time": "2021-11-11T04:17:38.002063",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-11T03:53:16.455762",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
